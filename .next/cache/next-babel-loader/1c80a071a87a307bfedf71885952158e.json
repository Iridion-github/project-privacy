{"ast":null,"code":"import path from 'path';\nimport slash from 'slash';\nimport { PdfReader } from \"pdfreader\"; //pacchetto usato per leggere i pdf \n\nimport fs from 'fs'; //pacchetto usato per leggere docx files\n\nimport mammoth from 'mammoth'; //pacchetto usato per convertire i docx in html\n\nimport WordExtractor from \"word-extractor\"; //pacchetto usato per leggere i doc files\n\nimport libre from 'libreoffice-convert-win'; //pacchetto usato per convertire i docx files in pdf\n\nconst winSlash = \"\\\\\";\nconst linSlash = \"/\";\nconst envSlash = linSlash; // ----------------------------- [Responds with an Object for every document in Archive] -----------------------------    \n\nexport default (async (req, res) => {\n  let conversionFinished = true;\n  let isArchiveMapped; //variabile bool che ci dirà se c'è una versione di oggi dell'archivio mappato\n\n  let mappedArchive; //variabile array dei dati dell'archivio mappato\n\n  const searchterms = req.query.searchterms;\n  const filesToAnalyze = [];\n  const dataToFilter = [];\n  const todayDate = new Date();\n  const todayUTC = todayDate.toUTCString();\n  const readFileName = todayUTC.slice(0, 16);\n\n  try {\n    const mappedArchiveRaw = await fs.readFileSync(\"mappedArchive\" + envSlash + readFileName + \".json\");\n    mappedArchive = JSON.parse(mappedArchiveRaw);\n    isArchiveMapped = true;\n    dataToFilter.push(...mappedArchive);\n  } catch (mappedArchiveMissing) {\n    console.log(mappedArchiveMissing);\n    isArchiveMapped = false;\n  }\n\n  if (!isArchiveMapped) {\n    //funzione che estrae i path precisi di ogni file all'interno della dir archive\n    function* getFiles(dir) {\n      const dirents = fs.readdirSync(dir, {\n        withFileTypes: true\n      });\n\n      for (const dirent of dirents) {\n        const fullpath = path.resolve(dir, dirent.name);\n\n        if (dirent.isDirectory()) {\n          yield* getFiles(fullpath);\n        } else {\n          yield {\n            fullpath: fullpath,\n            linuxfullpath: slash(fullpath),\n            relativepath: fullpath.split(\"public\" + envSlash)[1],\n            linuxpath: slash(fullpath.split(\"public\" + envSlash)[1]),\n            filename: dirent.name\n          };\n        }\n      }\n    }\n\n    (() => {\n      for (const f of getFiles('public/archive')) {\n        filesToAnalyze.push(f);\n      }\n    })(); //containerResult Promise starts pending\n\n\n    const containerResult = await new Promise((resolveContainer, rejectContainer) => {\n      try {\n        const analyzedFiles = [];\n        filesToAnalyze.forEach(async (fileObj, fileIndex) => {\n          const pdf = fileObj.fullpath.toLowerCase().includes(\".pdf\");\n          const docx = fileObj.fullpath.toLowerCase().includes(\".docx\");\n          const doc = fileObj.fullpath.toLowerCase().includes(\".doc\"); //singleResult Promise starts pending\n\n          const singleResult = await new Promise((resolveSingle, rejectSingle) => {\n            if (pdf) {\n              //[Pdf procedure] (PdfReader + manual array push)\n              const pdfBuffer = fs.readFileSync(fileObj.fullpath);\n\n              const getPdfContent = async () => {\n                const pdfContentArray = [];\n                await new PdfReader().parseFileItems(fileObj.fullpath, async (err, item) => {\n                  if (err) return rejectSingle(err); //rejecting singleResult Promise\n\n                  if (!item) {\n                    //Condizione d'uscita da parseFileItems()\n                    return resolveSingle({\n                      //resolving singleResult Promise\n                      fullpath: fileObj.fullpath,\n                      linuxfullpath: fileObj.linuxfullpath,\n                      filename: fileObj.filename,\n                      relativepath: fileObj.relativepath,\n                      linuxpath: fileObj.linuxpath,\n                      content: pdfContentArray.join(\" \")\n                    });\n                  }\n\n                  if (item.text) {\n                    //Per ogni frammento del pdf, pusho in pdfContentArray.\n                    pdfContentArray.push(item.text);\n                    return true;\n                  }\n                });\n              };\n\n              getPdfContent();\n            } else if (docx) {\n              //[Docx procedure] (mammoth)\n              const options = {};\n              mammoth.convertToHtml({\n                path: 'public' + envSlash + fileObj.relativepath\n              }, options).then(mammothResult => {\n                if (mammothResult.messages.length > 0) {\n                  for (let x; x < mammothResult.messages.length; x++) {\n                    console.log(\"\\n\\n Errors:\", mammothResult.messages[x], '\\n\\n');\n                  }\n                }\n\n                return resolveSingle({\n                  //resolving singleResult Promise\n                  fullpath: fileObj.fullpath,\n                  linuxfullpath: fileObj.linuxfullpath,\n                  filename: fileObj.filename,\n                  relativepath: fileObj.relativepath,\n                  linuxpath: fileObj.linuxpath,\n                  content: mammothResult.value\n                });\n              });\n            } else if (doc) {\n              //[Doc procedure] (WordExtractor)\n              const getDocContent = async fileObj => {\n                const docExtractor = new WordExtractor();\n                const extractedContent = await docExtractor.extract('public' + envSlash + fileObj.relativepath).then(function (doc) {\n                  resolveSingle({\n                    //resolving singleResult Promise\n                    fullpath: fileObj.fullpath,\n                    linuxfullpath: fileObj.linuxfullpath,\n                    filename: fileObj.filename,\n                    relativepath: fileObj.relativepath,\n                    linuxpath: fileObj.linuxpath,\n                    content: JSON.stringify(doc.getBody())\n                  });\n                });\n              };\n\n              getDocContent(fileObj);\n            } else {\n              rejectSingle(\"File is not pdf, docx or doc!\"); //rejecting singleResult Promise\n            }\n          }).then(singleResult => {\n            return singleResult;\n          }); //singleResult Promise resolved/rejected\n\n          await analyzedFiles.push({\n            fullpath: fileObj.fullpath,\n            filename: fileObj.filename,\n            relativepath: fileObj.relativepath,\n            linuxpath: fileObj.linuxpath,\n            content: singleResult.content\n          });\n\n          if (analyzedFiles.length === filesToAnalyze.length) {\n            //Qui dovrebbe salvare il json di containerResult\n            const mappedArchiveStr = JSON.stringify([...analyzedFiles]);\n            console.log(\"|||||||||||||||||||||||| started writing a json file representing the archive\");\n            const todayDate = new Date();\n            const todayUTC = todayDate.toUTCString();\n            const writeFileName = todayUTC.slice(0, 16);\n            await fs.writeFileSync(\"mappedArchive\" + envSlash + writeFileName + \".json\", mappedArchiveStr);\n            console.log(\"|||||||||||||||||||||||| finished writing json file\");\n            resolveContainer(analyzedFiles); //resolving containerResult Promise\n            //analyzedFiles is ready\n          } else {\n            console.log(\"(analyzedFiles.length !== filesToAnalyze.length) fileIndex attuale:\", fileIndex);\n          }\n        });\n      } catch (errContainer) {\n        console.log(\"rejectContainer with error:\", errContainer);\n        rejectContainer(errContainer); //rejecting containerResult Promise\n      }\n    }).then(async containerResult => {\n      dataToFilter.push(...containerResult);\n      return containerResult;\n    }); //containerResult Promise resolved/rejected\n  }\n\n  const filteredDocs = dataToFilter.filter(d => {\n    if (d.content) {\n      //Eventuali affinamenti del filtro andranno qui\n      const cleanContent = d.content.replace(/[^\\w\\s]/gi, '').toLowerCase();\n      return cleanContent.includes(searchterms.replace(/[^\\w\\s]/gi, '').toLowerCase());\n    } else {\n      return false;\n    }\n  });\n\n  const checkIfConversionNeeded = fileObjArr => {\n    const names = fileObjArr.map(el => el.filename);\n    return names.some(name => name.includes(\".docx\") || name.includes(\".doc\"));\n  };\n\n  if (checkIfConversionNeeded(filteredDocs)) {\n    let convertedDocs = [];\n    conversionFinished = false;\n\n    for (let x = 0; x < filteredDocs.length; x++) {\n      const d = filteredDocs[x];\n      const libreResult = await new Promise((resolveLibre, rejectLibre) => {\n        if (d && d.filename) {\n          const extend = '.pdf';\n          const enterPath = d.fullpath;\n          const outputPath = d.filename.includes(\".docx\") ? d.fullpath.split('.docx')[0] + extend : d.fullpath.split('.doc')[0] + extend;\n          const file = fs.readFileSync(enterPath);\n          libre.convert(file, extend, undefined, async (err, done) => {\n            if (err) {\n              console.log(`\\n\\n Error converting file: ${err} \\n\\n`);\n              rejectLibre(err);\n            } else {\n              // writeFileSync funziona, crea veramente il pdf, ma sarebbe troppo pesante farlo ogni volta per tutti i file, quindi mi limito a sfruttare il buffer: done.\n              //await fs.writeFileSync(outputPath, done)\n              resolveLibre(done);\n            }\n          });\n        } else {\n          console.log(\"Error - Caso inaspettato con questo file: \", filteredDocs[x]);\n        }\n      }).then(libreResult => {\n        return libreResult;\n      });\n      let mapResult = {};\n\n      if (libreResult && libreResult.byteLength) {\n        mapResult = {\n          fullpath: d.fullpath,\n          filename: d.filename,\n          relativepath: d.relativepath,\n          linuxpath: d.linuxpath,\n          content: d.filename.includes(\".docx\") ? d.content : \"\",\n          buffer: libreResult\n        };\n      } else {\n        mapResult = {\n          fullpath: d.fullpath,\n          filename: d.filename,\n          relativepath: d.relativepath,\n          linuxpath: d.linuxpath,\n          content: d.filename.includes(\".docx\") ? d.content : \"\"\n        };\n      }\n\n      const updateConvertedDocs = (convertedArr, originalArr) => {\n        const resultArr = [...convertedArr, mapResult];\n\n        if (resultArr.length === originalArr.length) {\n          conversionFinished = true;\n        }\n\n        return resultArr;\n      };\n\n      convertedDocs = await updateConvertedDocs(convertedDocs, filteredDocs);\n    }\n\n    (function forceWait() {\n      if (!conversionFinished) {\n        setTimeout(forceWait, 1000);\n      } else {\n        return res.status(200).json({\n          //Success - Trovato qualcosa per i searchterms immessi, e nessun errore.\n          success: true,\n          data: {\n            filteredDocs: convertedDocs\n          }\n        });\n      }\n    })();\n  } else {\n    return res.status(200).json({\n      //Success - Trovato qualcosa per i searchterms immessi, e nessun errore.\n      success: true,\n      data: {\n        filteredDocs: filteredDocs\n      }\n    });\n  }\n});","map":{"version":3,"sources":["/home/iridion/Desktop/Repos/Freelancer/project-privacy/pages/api/archive/search.js"],"names":["path","slash","PdfReader","fs","mammoth","WordExtractor","libre","winSlash","linSlash","envSlash","req","res","conversionFinished","isArchiveMapped","mappedArchive","searchterms","query","filesToAnalyze","dataToFilter","todayDate","Date","todayUTC","toUTCString","readFileName","slice","mappedArchiveRaw","readFileSync","JSON","parse","push","mappedArchiveMissing","console","log","getFiles","dir","dirents","readdirSync","withFileTypes","dirent","fullpath","resolve","name","isDirectory","linuxfullpath","relativepath","split","linuxpath","filename","f","containerResult","Promise","resolveContainer","rejectContainer","analyzedFiles","forEach","fileObj","fileIndex","pdf","toLowerCase","includes","docx","doc","singleResult","resolveSingle","rejectSingle","pdfBuffer","getPdfContent","pdfContentArray","parseFileItems","err","item","content","join","text","options","convertToHtml","then","mammothResult","messages","length","x","value","getDocContent","docExtractor","extractedContent","extract","stringify","getBody","mappedArchiveStr","writeFileName","writeFileSync","errContainer","filteredDocs","filter","d","cleanContent","replace","checkIfConversionNeeded","fileObjArr","names","map","el","some","convertedDocs","libreResult","resolveLibre","rejectLibre","extend","enterPath","outputPath","file","convert","undefined","done","mapResult","byteLength","buffer","updateConvertedDocs","convertedArr","originalArr","resultArr","forceWait","setTimeout","status","json","success","data"],"mappings":"AAAA,OAAOA,IAAP,MAAiB,MAAjB;AACA,OAAOC,KAAP,MAAkB,OAAlB;AACA,SAASC,SAAT,QAA0B,WAA1B,C,CAAuC;;AACvC,OAAOC,EAAP,MAAe,IAAf,C,CAAmB;;AACnB,OAAOC,OAAP,MAAoB,SAApB,C,CAA8B;;AAC9B,OAAOC,aAAP,MAA0B,gBAA1B,C,CAA2C;;AAC3C,OAAOC,KAAP,MAAkB,yBAAlB,C,CAA4C;;AAE5C,MAAMC,QAAQ,GAAG,IAAjB;AAEA,MAAMC,QAAQ,GAAG,GAAjB;AAEA,MAAMC,QAAQ,GAAGD,QAAjB,C,CAEA;;AACA,gBAAe,OAAOE,GAAP,EAAYC,GAAZ,KAAoB;AACjC,MAAIC,kBAAkB,GAAG,IAAzB;AACA,MAAIC,eAAJ,CAFiC,CAEb;;AACpB,MAAIC,aAAJ,CAHiC,CAGf;;AAClB,QAAMC,WAAW,GAAGL,GAAG,CAACM,KAAJ,CAAUD,WAA9B;AACA,QAAME,cAAc,GAAG,EAAvB;AACA,QAAMC,YAAY,GAAG,EAArB;AACA,QAAMC,SAAS,GAAG,IAAIC,IAAJ,EAAlB;AACA,QAAMC,QAAQ,GAAGF,SAAS,CAACG,WAAV,EAAjB;AACA,QAAMC,YAAY,GAAGF,QAAQ,CAACG,KAAT,CAAe,CAAf,EAAkB,EAAlB,CAArB;;AACA,MAAI;AACF,UAAMC,gBAAgB,GAAG,MAAMtB,EAAE,CAACuB,YAAH,CAAgB,kBAAkBjB,QAAlB,GAA6Bc,YAA7B,GAA4C,OAA5D,CAA/B;AACAT,IAAAA,aAAa,GAAGa,IAAI,CAACC,KAAL,CAAWH,gBAAX,CAAhB;AACAZ,IAAAA,eAAe,GAAG,IAAlB;AACAK,IAAAA,YAAY,CAACW,IAAb,CAAkB,GAAGf,aAArB;AACD,GALD,CAKE,OAAOgB,oBAAP,EAA6B;AAC7BC,IAAAA,OAAO,CAACC,GAAR,CAAYF,oBAAZ;AACAjB,IAAAA,eAAe,GAAG,KAAlB;AACD;;AAED,MAAI,CAACA,eAAL,EAAsB;AACpB;AACA,cAAUoB,QAAV,CAAmBC,GAAnB,EAAwB;AACtB,YAAMC,OAAO,GAAGhC,EAAE,CAACiC,WAAH,CAAeF,GAAf,EAAoB;AAAEG,QAAAA,aAAa,EAAE;AAAjB,OAApB,CAAhB;;AACA,WAAK,MAAMC,MAAX,IAAqBH,OAArB,EAA8B;AAC5B,cAAMI,QAAQ,GAAGvC,IAAI,CAACwC,OAAL,CAAaN,GAAb,EAAkBI,MAAM,CAACG,IAAzB,CAAjB;;AACA,YAAIH,MAAM,CAACI,WAAP,EAAJ,EAA0B;AACxB,iBAAOT,QAAQ,CAACM,QAAD,CAAf;AACD,SAFD,MAEO;AACL,gBAAM;AACJA,YAAAA,QAAQ,EAAEA,QADN;AAEJI,YAAAA,aAAa,EAAE1C,KAAK,CAACsC,QAAD,CAFhB;AAGJK,YAAAA,YAAY,EAAEL,QAAQ,CAACM,KAAT,CAAe,WAAWpC,QAA1B,EAAoC,CAApC,CAHV;AAIJqC,YAAAA,SAAS,EAAE7C,KAAK,CAACsC,QAAQ,CAACM,KAAT,CAAe,WAAWpC,QAA1B,EAAoC,CAApC,CAAD,CAJZ;AAKJsC,YAAAA,QAAQ,EAAET,MAAM,CAACG;AALb,WAAN;AAOD;AACF;AACF;;AACD,KAAC,MAAM;AACL,WAAK,MAAMO,CAAX,IAAgBf,QAAQ,CAAC,gBAAD,CAAxB,EAA4C;AAC1ChB,QAAAA,cAAc,CAACY,IAAf,CAAoBmB,CAApB;AACD;AACF,KAJD,IAnBoB,CAyBpB;;;AACA,UAAMC,eAAe,GAAG,MAAM,IAAIC,OAAJ,CAAY,CAACC,gBAAD,EAAmBC,eAAnB,KAAuC;AAC/E,UAAI;AACF,cAAMC,aAAa,GAAG,EAAtB;AACApC,QAAAA,cAAc,CAACqC,OAAf,CAAuB,OAAOC,OAAP,EAAgBC,SAAhB,KAA8B;AACnD,gBAAMC,GAAG,GAAGF,OAAO,CAAChB,QAAR,CAAiBmB,WAAjB,GAA+BC,QAA/B,CAAwC,MAAxC,CAAZ;AACA,gBAAMC,IAAI,GAAGL,OAAO,CAAChB,QAAR,CAAiBmB,WAAjB,GAA+BC,QAA/B,CAAwC,OAAxC,CAAb;AACA,gBAAME,GAAG,GAAGN,OAAO,CAAChB,QAAR,CAAiBmB,WAAjB,GAA+BC,QAA/B,CAAwC,MAAxC,CAAZ,CAHmD,CAKnD;;AACA,gBAAMG,YAAY,GAAG,MAAM,IAAIZ,OAAJ,CAAY,CAACa,aAAD,EAAgBC,YAAhB,KAAiC;AACtE,gBAAIP,GAAJ,EAAS;AAAE;AACT,oBAAMQ,SAAS,GAAG9D,EAAE,CAACuB,YAAH,CAAgB6B,OAAO,CAAChB,QAAxB,CAAlB;;AACA,oBAAM2B,aAAa,GAAG,YAAY;AAChC,sBAAMC,eAAe,GAAG,EAAxB;AACA,sBAAM,IAAIjE,SAAJ,GAAgBkE,cAAhB,CAA+Bb,OAAO,CAAChB,QAAvC,EAAiD,OAAO8B,GAAP,EAAYC,IAAZ,KAAqB;AAC1E,sBAAID,GAAJ,EAAS,OAAOL,YAAY,CAACK,GAAD,CAAnB,CADiE,CACxC;;AAClC,sBAAI,CAACC,IAAL,EAAW;AAAE;AACX,2BAAOP,aAAa,CAAC;AAAE;AACrBxB,sBAAAA,QAAQ,EAAEgB,OAAO,CAAChB,QADC;AAEnBI,sBAAAA,aAAa,EAAEY,OAAO,CAACZ,aAFJ;AAGnBI,sBAAAA,QAAQ,EAAEQ,OAAO,CAACR,QAHC;AAInBH,sBAAAA,YAAY,EAAEW,OAAO,CAACX,YAJH;AAKnBE,sBAAAA,SAAS,EAAES,OAAO,CAACT,SALA;AAMnByB,sBAAAA,OAAO,EAAEJ,eAAe,CAACK,IAAhB,CAAqB,GAArB;AANU,qBAAD,CAApB;AAQD;;AACD,sBAAIF,IAAI,CAACG,IAAT,EAAe;AAAE;AACfN,oBAAAA,eAAe,CAACtC,IAAhB,CAAqByC,IAAI,CAACG,IAA1B;AACA,2BAAO,IAAP;AACD;AACF,iBAhBK,CAAN;AAiBD,eAnBD;;AAoBAP,cAAAA,aAAa;AACd,aAvBD,MAuBO,IAAIN,IAAJ,EAAU;AACf;AACA,oBAAMc,OAAO,GAAG,EAAhB;AACAtE,cAAAA,OAAO,CAACuE,aAAR,CAAsB;AAAE3E,gBAAAA,IAAI,EAAE,WAAWS,QAAX,GAAsB8C,OAAO,CAACX;AAAtC,eAAtB,EAA4E8B,OAA5E,EAAqFE,IAArF,CAA2FC,aAAD,IAAmB;AAC3G,oBAAIA,aAAa,CAACC,QAAd,CAAuBC,MAAvB,GAAgC,CAApC,EAAuC;AACrC,uBAAK,IAAIC,CAAT,EAAYA,CAAC,GAAGH,aAAa,CAACC,QAAd,CAAuBC,MAAvC,EAA+CC,CAAC,EAAhD,EAAoD;AAClDjD,oBAAAA,OAAO,CAACC,GAAR,CAAY,cAAZ,EAA4B6C,aAAa,CAACC,QAAd,CAAuBE,CAAvB,CAA5B,EAAuD,MAAvD;AACD;AACF;;AACD,uBAAOjB,aAAa,CAAC;AAAE;AACrBxB,kBAAAA,QAAQ,EAAEgB,OAAO,CAAChB,QADC;AAEnBI,kBAAAA,aAAa,EAAEY,OAAO,CAACZ,aAFJ;AAGnBI,kBAAAA,QAAQ,EAAEQ,OAAO,CAACR,QAHC;AAInBH,kBAAAA,YAAY,EAAEW,OAAO,CAACX,YAJH;AAKnBE,kBAAAA,SAAS,EAAES,OAAO,CAACT,SALA;AAMnByB,kBAAAA,OAAO,EAAEM,aAAa,CAACI;AANJ,iBAAD,CAApB;AAQD,eAdD;AAeD,aAlBM,MAkBA,IAAIpB,GAAJ,EAAS;AAAE;AAChB,oBAAMqB,aAAa,GAAG,MAAO3B,OAAP,IAAmB;AACvC,sBAAM4B,YAAY,GAAG,IAAI9E,aAAJ,EAArB;AACA,sBAAM+E,gBAAgB,GAAG,MAAMD,YAAY,CAACE,OAAb,CAAqB,WAAW5E,QAAX,GAAsB8C,OAAO,CAACX,YAAnD,EAAiEgC,IAAjE,CAAsE,UAAUf,GAAV,EAAe;AAClHE,kBAAAA,aAAa,CAAC;AAAE;AACdxB,oBAAAA,QAAQ,EAAEgB,OAAO,CAAChB,QADN;AAEZI,oBAAAA,aAAa,EAAEY,OAAO,CAACZ,aAFX;AAGZI,oBAAAA,QAAQ,EAAEQ,OAAO,CAACR,QAHN;AAIZH,oBAAAA,YAAY,EAAEW,OAAO,CAACX,YAJV;AAKZE,oBAAAA,SAAS,EAAES,OAAO,CAACT,SALP;AAMZyB,oBAAAA,OAAO,EAAE5C,IAAI,CAAC2D,SAAL,CAAezB,GAAG,CAAC0B,OAAJ,EAAf;AANG,mBAAD,CAAb;AAQD,iBAT8B,CAA/B;AAUD,eAZD;;AAaAL,cAAAA,aAAa,CAAC3B,OAAD,CAAb;AACD,aAfM,MAeA;AACLS,cAAAA,YAAY,CAAC,+BAAD,CAAZ,CADK,CACyC;AAC/C;AACF,WA5D0B,EA4DxBY,IA5DwB,CA4DnBd,YAAY,IAAI;AACtB,mBAAOA,YAAP;AACD,WA9D0B,CAA3B,CANmD,CAqEnD;;AAEA,gBAAMT,aAAa,CAACxB,IAAd,CAAmB;AACvBU,YAAAA,QAAQ,EAAEgB,OAAO,CAAChB,QADK;AAEvBQ,YAAAA,QAAQ,EAAEQ,OAAO,CAACR,QAFK;AAGvBH,YAAAA,YAAY,EAAEW,OAAO,CAACX,YAHC;AAIvBE,YAAAA,SAAS,EAAES,OAAO,CAACT,SAJI;AAKvByB,YAAAA,OAAO,EAAET,YAAY,CAACS;AALC,WAAnB,CAAN;;AAQA,cAAIlB,aAAa,CAAC0B,MAAd,KAAyB9D,cAAc,CAAC8D,MAA5C,EAAoD;AAClD;AACA,kBAAMS,gBAAgB,GAAG7D,IAAI,CAAC2D,SAAL,CAAe,CAAC,GAAGjC,aAAJ,CAAf,CAAzB;AACAtB,YAAAA,OAAO,CAACC,GAAR,CAAY,+EAAZ;AACA,kBAAMb,SAAS,GAAG,IAAIC,IAAJ,EAAlB;AACA,kBAAMC,QAAQ,GAAGF,SAAS,CAACG,WAAV,EAAjB;AACA,kBAAMmE,aAAa,GAAGpE,QAAQ,CAACG,KAAT,CAAe,CAAf,EAAkB,EAAlB,CAAtB;AACA,kBAAMrB,EAAE,CAACuF,aAAH,CAAiB,kBAAkBjF,QAAlB,GAA6BgF,aAA7B,GAA6C,OAA9D,EAAuED,gBAAvE,CAAN;AACAzD,YAAAA,OAAO,CAACC,GAAR,CAAY,qDAAZ;AACAmB,YAAAA,gBAAgB,CAACE,aAAD,CAAhB,CATkD,CASlB;AAChC;AACD,WAXD,MAWO;AACLtB,YAAAA,OAAO,CAACC,GAAR,CAAY,qEAAZ,EAAmFwB,SAAnF;AACD;AACF,SA7FD;AA8FD,OAhGD,CAgGE,OAAOmC,YAAP,EAAqB;AACrB5D,QAAAA,OAAO,CAACC,GAAR,CAAY,6BAAZ,EAA2C2D,YAA3C;AACAvC,QAAAA,eAAe,CAACuC,YAAD,CAAf,CAFqB,CAES;AAC/B;AACF,KArG6B,EAqG3Bf,IArG2B,CAqGtB,MAAO3B,eAAP,IAA2B;AACjC/B,MAAAA,YAAY,CAACW,IAAb,CAAkB,GAAGoB,eAArB;AACA,aAAOA,eAAP;AACD,KAxG6B,CAA9B,CA1BoB,CAkIlB;AACH;;AAED,QAAM2C,YAAY,GAAG1E,YAAY,CAAC2E,MAAb,CAAoBC,CAAC,IAAI;AAC5C,QAAIA,CAAC,CAACvB,OAAN,EAAe;AACb;AACA,YAAMwB,YAAY,GAAGD,CAAC,CAACvB,OAAF,CAAUyB,OAAV,CAAkB,WAAlB,EAA+B,EAA/B,EAAmCtC,WAAnC,EAArB;AACA,aAAOqC,YAAY,CAACpC,QAAb,CAAsB5C,WAAW,CAACiF,OAAZ,CAAoB,WAApB,EAAiC,EAAjC,EAAqCtC,WAArC,EAAtB,CAAP;AACD,KAJD,MAIO;AACL,aAAO,KAAP;AACD;AACF,GARoB,CAArB;;AAUA,QAAMuC,uBAAuB,GAAIC,UAAD,IAAgB;AAC9C,UAAMC,KAAK,GAAGD,UAAU,CAACE,GAAX,CAAeC,EAAE,IAAIA,EAAE,CAACtD,QAAxB,CAAd;AACA,WAAOoD,KAAK,CAACG,IAAN,CAAW7D,IAAI,IAAKA,IAAI,CAACkB,QAAL,CAAc,OAAd,KAA0BlB,IAAI,CAACkB,QAAL,CAAc,MAAd,CAA9C,CAAP;AACD,GAHD;;AAKA,MAAIsC,uBAAuB,CAACL,YAAD,CAA3B,EAA2C;AACzC,QAAIW,aAAa,GAAG,EAApB;AACA3F,IAAAA,kBAAkB,GAAG,KAArB;;AAEA,SAAK,IAAIoE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGY,YAAY,CAACb,MAAjC,EAAyCC,CAAC,EAA1C,EAA8C;AAC5C,YAAMc,CAAC,GAAGF,YAAY,CAACZ,CAAD,CAAtB;AACA,YAAMwB,WAAW,GAAG,MAAM,IAAItD,OAAJ,CAAY,CAACuD,YAAD,EAAeC,WAAf,KAA+B;AACnE,YAAIZ,CAAC,IAAIA,CAAC,CAAC/C,QAAX,EAAqB;AACnB,gBAAM4D,MAAM,GAAG,MAAf;AACA,gBAAMC,SAAS,GAAGd,CAAC,CAACvD,QAApB;AACA,gBAAMsE,UAAU,GAAGf,CAAC,CAAC/C,QAAF,CAAWY,QAAX,CAAoB,OAApB,IAA+BmC,CAAC,CAACvD,QAAF,CAAWM,KAAX,CAAiB,OAAjB,EAA0B,CAA1B,IAA+B8D,MAA9D,GAAuEb,CAAC,CAACvD,QAAF,CAAWM,KAAX,CAAiB,MAAjB,EAAyB,CAAzB,IAA8B8D,MAAxH;AACA,gBAAMG,IAAI,GAAG3G,EAAE,CAACuB,YAAH,CAAgBkF,SAAhB,CAAb;AACAtG,UAAAA,KAAK,CAACyG,OAAN,CAAcD,IAAd,EAAoBH,MAApB,EAA4BK,SAA5B,EAAuC,OAAO3C,GAAP,EAAY4C,IAAZ,KAAqB;AAC1D,gBAAI5C,GAAJ,EAAS;AACPtC,cAAAA,OAAO,CAACC,GAAR,CAAa,+BAA8BqC,GAAI,OAA/C;AACAqC,cAAAA,WAAW,CAACrC,GAAD,CAAX;AACD,aAHD,MAGO;AACL;AACA;AACAoC,cAAAA,YAAY,CAACQ,IAAD,CAAZ;AACD;AACF,WATD;AAUD,SAfD,MAeO;AACLlF,UAAAA,OAAO,CAACC,GAAR,CAAY,4CAAZ,EAA0D4D,YAAY,CAACZ,CAAD,CAAtE;AACD;AACF,OAnByB,EAmBvBJ,IAnBuB,CAmBlB4B,WAAW,IAAI;AACrB,eAAOA,WAAP;AACD,OArByB,CAA1B;AAuBA,UAAIU,SAAS,GAAG,EAAhB;;AAEA,UAAIV,WAAW,IAAIA,WAAW,CAACW,UAA/B,EAA2C;AACzCD,QAAAA,SAAS,GAAG;AACV3E,UAAAA,QAAQ,EAAEuD,CAAC,CAACvD,QADF;AAEVQ,UAAAA,QAAQ,EAAE+C,CAAC,CAAC/C,QAFF;AAGVH,UAAAA,YAAY,EAAEkD,CAAC,CAAClD,YAHN;AAIVE,UAAAA,SAAS,EAAEgD,CAAC,CAAChD,SAJH;AAKVyB,UAAAA,OAAO,EAAEuB,CAAC,CAAC/C,QAAF,CAAWY,QAAX,CAAoB,OAApB,IAA+BmC,CAAC,CAACvB,OAAjC,GAA2C,EAL1C;AAMV6C,UAAAA,MAAM,EAAEZ;AANE,SAAZ;AAQD,OATD,MASO;AACLU,QAAAA,SAAS,GAAG;AACV3E,UAAAA,QAAQ,EAAEuD,CAAC,CAACvD,QADF;AAEVQ,UAAAA,QAAQ,EAAE+C,CAAC,CAAC/C,QAFF;AAGVH,UAAAA,YAAY,EAAEkD,CAAC,CAAClD,YAHN;AAIVE,UAAAA,SAAS,EAAEgD,CAAC,CAAChD,SAJH;AAKVyB,UAAAA,OAAO,EAAEuB,CAAC,CAAC/C,QAAF,CAAWY,QAAX,CAAoB,OAApB,IAA+BmC,CAAC,CAACvB,OAAjC,GAA2C;AAL1C,SAAZ;AAOD;;AAED,YAAM8C,mBAAmB,GAAG,CAACC,YAAD,EAAeC,WAAf,KAA+B;AACzD,cAAMC,SAAS,GAAG,CAAC,GAAGF,YAAJ,EAAkBJ,SAAlB,CAAlB;;AACA,YAAIM,SAAS,CAACzC,MAAV,KAAqBwC,WAAW,CAACxC,MAArC,EAA6C;AAC3CnE,UAAAA,kBAAkB,GAAG,IAArB;AACD;;AACD,eAAO4G,SAAP;AACD,OAND;;AAQAjB,MAAAA,aAAa,GAAG,MAAMc,mBAAmB,CAACd,aAAD,EAAgBX,YAAhB,CAAzC;AACD;;AAED,KAAC,SAAS6B,SAAT,GAAqB;AACpB,UAAI,CAAC7G,kBAAL,EAAyB;AACvB8G,QAAAA,UAAU,CAACD,SAAD,EAAY,IAAZ,CAAV;AACD,OAFD,MAEO;AACL,eAAO9G,GAAG,CAACgH,MAAJ,CAAW,GAAX,EAAgBC,IAAhB,CAAqB;AAAE;AAC5BC,UAAAA,OAAO,EAAE,IADiB;AAE1BC,UAAAA,IAAI,EAAE;AAAElC,YAAAA,YAAY,EAAEW;AAAhB;AAFoB,SAArB,CAAP;AAID;AACF,KATD;AAUD,GAvED,MAuEO;AACL,WAAO5F,GAAG,CAACgH,MAAJ,CAAW,GAAX,EAAgBC,IAAhB,CAAqB;AAAE;AAC5BC,MAAAA,OAAO,EAAE,IADiB;AAE1BC,MAAAA,IAAI,EAAE;AAAElC,QAAAA,YAAY,EAAEA;AAAhB;AAFoB,KAArB,CAAP;AAID;AACF,CArPD","sourcesContent":["import path from 'path'\nimport slash from 'slash'\nimport { PdfReader } from \"pdfreader\"  //pacchetto usato per leggere i pdf \nimport fs from 'fs'//pacchetto usato per leggere docx files\nimport mammoth from 'mammoth' //pacchetto usato per convertire i docx in html\nimport WordExtractor from \"word-extractor\" //pacchetto usato per leggere i doc files\nimport libre from 'libreoffice-convert-win' //pacchetto usato per convertire i docx files in pdf\n\nconst winSlash = \"\\\\\"\n\nconst linSlash = \"/\"\n\nconst envSlash = linSlash\n\n// ----------------------------- [Responds with an Object for every document in Archive] -----------------------------    \nexport default async (req, res) => {\n  let conversionFinished = true\n  let isArchiveMapped //variabile bool che ci dirà se c'è una versione di oggi dell'archivio mappato\n  let mappedArchive //variabile array dei dati dell'archivio mappato\n  const searchterms = req.query.searchterms\n  const filesToAnalyze = []\n  const dataToFilter = []\n  const todayDate = new Date()\n  const todayUTC = todayDate.toUTCString()\n  const readFileName = todayUTC.slice(0, 16)\n  try {\n    const mappedArchiveRaw = await fs.readFileSync(\"mappedArchive\" + envSlash + readFileName + \".json\")\n    mappedArchive = JSON.parse(mappedArchiveRaw)\n    isArchiveMapped = true\n    dataToFilter.push(...mappedArchive)\n  } catch (mappedArchiveMissing) {\n    console.log(mappedArchiveMissing)\n    isArchiveMapped = false\n  }\n\n  if (!isArchiveMapped) {\n    //funzione che estrae i path precisi di ogni file all'interno della dir archive\n    function* getFiles(dir) {\n      const dirents = fs.readdirSync(dir, { withFileTypes: true })\n      for (const dirent of dirents) {\n        const fullpath = path.resolve(dir, dirent.name)\n        if (dirent.isDirectory()) {\n          yield* getFiles(fullpath)\n        } else {\n          yield {\n            fullpath: fullpath,\n            linuxfullpath: slash(fullpath),\n            relativepath: fullpath.split(\"public\" + envSlash)[1],\n            linuxpath: slash(fullpath.split(\"public\" + envSlash)[1]),\n            filename: dirent.name\n          }\n        }\n      }\n    }\n    (() => {\n      for (const f of getFiles('public/archive')) {\n        filesToAnalyze.push(f)\n      }\n    })()\n\n    //containerResult Promise starts pending\n    const containerResult = await new Promise((resolveContainer, rejectContainer) => {\n      try {\n        const analyzedFiles = []\n        filesToAnalyze.forEach(async (fileObj, fileIndex) => {\n          const pdf = fileObj.fullpath.toLowerCase().includes(\".pdf\")\n          const docx = fileObj.fullpath.toLowerCase().includes(\".docx\")\n          const doc = fileObj.fullpath.toLowerCase().includes(\".doc\")\n\n          //singleResult Promise starts pending\n          const singleResult = await new Promise((resolveSingle, rejectSingle) => {\n            if (pdf) { //[Pdf procedure] (PdfReader + manual array push)\n              const pdfBuffer = fs.readFileSync(fileObj.fullpath)\n              const getPdfContent = async () => {\n                const pdfContentArray = []\n                await new PdfReader().parseFileItems(fileObj.fullpath, async (err, item) => {\n                  if (err) return rejectSingle(err) //rejecting singleResult Promise\n                  if (!item) { //Condizione d'uscita da parseFileItems()\n                    return resolveSingle({ //resolving singleResult Promise\n                      fullpath: fileObj.fullpath,\n                      linuxfullpath: fileObj.linuxfullpath,\n                      filename: fileObj.filename,\n                      relativepath: fileObj.relativepath,\n                      linuxpath: fileObj.linuxpath,\n                      content: pdfContentArray.join(\" \")\n                    })\n                  }\n                  if (item.text) { //Per ogni frammento del pdf, pusho in pdfContentArray.\n                    pdfContentArray.push(item.text)\n                    return true\n                  }\n                })\n              }\n              getPdfContent()\n            } else if (docx) {\n              //[Docx procedure] (mammoth)\n              const options = {}\n              mammoth.convertToHtml({ path: 'public' + envSlash + fileObj.relativepath }, options).then((mammothResult) => {\n                if (mammothResult.messages.length > 0) {\n                  for (let x; x < mammothResult.messages.length; x++) {\n                    console.log(\"\\n\\n Errors:\", mammothResult.messages[x], '\\n\\n')\n                  }\n                }\n                return resolveSingle({ //resolving singleResult Promise\n                  fullpath: fileObj.fullpath,\n                  linuxfullpath: fileObj.linuxfullpath,\n                  filename: fileObj.filename,\n                  relativepath: fileObj.relativepath,\n                  linuxpath: fileObj.linuxpath,\n                  content: mammothResult.value\n                })\n              })\n            } else if (doc) { //[Doc procedure] (WordExtractor)\n              const getDocContent = async (fileObj) => {\n                const docExtractor = new WordExtractor()\n                const extractedContent = await docExtractor.extract('public' + envSlash + fileObj.relativepath).then(function (doc) {\n                  resolveSingle({ //resolving singleResult Promise\n                    fullpath: fileObj.fullpath,\n                    linuxfullpath: fileObj.linuxfullpath,\n                    filename: fileObj.filename,\n                    relativepath: fileObj.relativepath,\n                    linuxpath: fileObj.linuxpath,\n                    content: JSON.stringify(doc.getBody())\n                  })\n                })\n              }\n              getDocContent(fileObj)\n            } else {\n              rejectSingle(\"File is not pdf, docx or doc!\") //rejecting singleResult Promise\n            }\n          }).then(singleResult => {\n            return singleResult\n          })\n          //singleResult Promise resolved/rejected\n\n          await analyzedFiles.push({\n            fullpath: fileObj.fullpath,\n            filename: fileObj.filename,\n            relativepath: fileObj.relativepath,\n            linuxpath: fileObj.linuxpath,\n            content: singleResult.content\n          })\n\n          if (analyzedFiles.length === filesToAnalyze.length) {\n            //Qui dovrebbe salvare il json di containerResult\n            const mappedArchiveStr = JSON.stringify([...analyzedFiles])\n            console.log(\"|||||||||||||||||||||||| started writing a json file representing the archive\")\n            const todayDate = new Date()\n            const todayUTC = todayDate.toUTCString()\n            const writeFileName = todayUTC.slice(0, 16)\n            await fs.writeFileSync(\"mappedArchive\" + envSlash + writeFileName + \".json\", mappedArchiveStr)\n            console.log(\"|||||||||||||||||||||||| finished writing json file\")\n            resolveContainer(analyzedFiles) //resolving containerResult Promise\n            //analyzedFiles is ready\n          } else {\n            console.log(\"(analyzedFiles.length !== filesToAnalyze.length) fileIndex attuale:\", fileIndex)\n          }\n        })\n      } catch (errContainer) {\n        console.log(\"rejectContainer with error:\", errContainer)\n        rejectContainer(errContainer) //rejecting containerResult Promise\n      }\n    }).then(async (containerResult) => {\n      dataToFilter.push(...containerResult)\n      return containerResult\n    })//containerResult Promise resolved/rejected\n  }\n\n  const filteredDocs = dataToFilter.filter(d => {\n    if (d.content) {\n      //Eventuali affinamenti del filtro andranno qui\n      const cleanContent = d.content.replace(/[^\\w\\s]/gi, '').toLowerCase()\n      return cleanContent.includes(searchterms.replace(/[^\\w\\s]/gi, '').toLowerCase())\n    } else {\n      return false\n    }\n  })\n\n  const checkIfConversionNeeded = (fileObjArr) => {\n    const names = fileObjArr.map(el => el.filename)\n    return names.some(name => (name.includes(\".docx\") || name.includes(\".doc\")))\n  }\n\n  if (checkIfConversionNeeded(filteredDocs)) {\n    let convertedDocs = []\n    conversionFinished = false\n\n    for (let x = 0; x < filteredDocs.length; x++) {\n      const d = filteredDocs[x]\n      const libreResult = await new Promise((resolveLibre, rejectLibre) => {\n        if (d && d.filename) {\n          const extend = '.pdf'\n          const enterPath = d.fullpath\n          const outputPath = d.filename.includes(\".docx\") ? d.fullpath.split('.docx')[0] + extend : d.fullpath.split('.doc')[0] + extend\n          const file = fs.readFileSync(enterPath)\n          libre.convert(file, extend, undefined, async (err, done) => {\n            if (err) {\n              console.log(`\\n\\n Error converting file: ${err} \\n\\n`)\n              rejectLibre(err)\n            } else {\n              // writeFileSync funziona, crea veramente il pdf, ma sarebbe troppo pesante farlo ogni volta per tutti i file, quindi mi limito a sfruttare il buffer: done.\n              //await fs.writeFileSync(outputPath, done)\n              resolveLibre(done)\n            }\n          })\n        } else {\n          console.log(\"Error - Caso inaspettato con questo file: \", filteredDocs[x])\n        }\n      }).then(libreResult => {\n        return libreResult\n      })\n\n      let mapResult = {}\n\n      if (libreResult && libreResult.byteLength) {\n        mapResult = {\n          fullpath: d.fullpath,\n          filename: d.filename,\n          relativepath: d.relativepath,\n          linuxpath: d.linuxpath,\n          content: d.filename.includes(\".docx\") ? d.content : \"\",\n          buffer: libreResult\n        }\n      } else {\n        mapResult = {\n          fullpath: d.fullpath,\n          filename: d.filename,\n          relativepath: d.relativepath,\n          linuxpath: d.linuxpath,\n          content: d.filename.includes(\".docx\") ? d.content : \"\"\n        }\n      }\n\n      const updateConvertedDocs = (convertedArr, originalArr) => {\n        const resultArr = [...convertedArr, mapResult]\n        if (resultArr.length === originalArr.length) {\n          conversionFinished = true\n        }\n        return resultArr\n      }\n\n      convertedDocs = await updateConvertedDocs(convertedDocs, filteredDocs)\n    }\n\n    (function forceWait() {\n      if (!conversionFinished) {\n        setTimeout(forceWait, 1000)\n      } else {\n        return res.status(200).json({ //Success - Trovato qualcosa per i searchterms immessi, e nessun errore.\n          success: true,\n          data: { filteredDocs: convertedDocs }\n        })\n      }\n    })()\n  } else {\n    return res.status(200).json({ //Success - Trovato qualcosa per i searchterms immessi, e nessun errore.\n      success: true,\n      data: { filteredDocs: filteredDocs }\n    })\n  }\n}"]},"metadata":{},"sourceType":"module"}