{"ast":null,"code":"import path from 'path';\nimport slash from 'slash';\nimport { PdfReader } from \"pdfreader\"; //pacchetto usato per leggere i pdf \n\nimport fs from 'fs'; //pacchetto usato per leggere docx files\n\nimport mammoth from 'mammoth'; //pacchetto usato per convertire i docx in html\n\nimport WordExtractor from \"word-extractor\"; //pacchetto usato per leggere i doc files\n//import libre from 'libreoffice-convert-win' //pacchetto usato per convertire i docx files in pdf (windows version)\n\nimport libre from 'libreoffice-convert'; //pacchetto usato per convertire i docx files in pdf (linux version)\n\nconst environment = \"linux\";\nconst envSlash = environment === \"windows\" ? \"\\\\\" : \"/\"; // ----------------------------- [Responds with an Object for every document in Archive] -----------------------------    \n\nexport default (async (req, res) => {\n  let conversionFinished = true;\n  let isArchiveMapped; //variabile bool che ci dirà se c'è una versione di oggi dell'archivio mappato\n\n  let mappedArchive; //variabile array dei dati dell'archivio mappato\n\n  const searchterms = req.query.searchterms;\n  const filesToAnalyze = [];\n  const dataToFilter = [];\n  const todayDate = new Date();\n  const todayUTC = todayDate.toUTCString();\n  const readFileName = todayUTC.slice(0, 16);\n\n  try {\n    const mappedArchiveRaw = await fs.readFileSync(\"mappedArchive\" + envSlash + readFileName + \".json\");\n    mappedArchive = JSON.parse(mappedArchiveRaw);\n    isArchiveMapped = true;\n    dataToFilter.push(...mappedArchive);\n  } catch (mappedArchiveMissing) {\n    console.log(mappedArchiveMissing);\n    isArchiveMapped = false;\n  }\n\n  if (!isArchiveMapped) {\n    //funzione che estrae i path precisi di ogni file all'interno della dir archive\n    function* getFiles(dir) {\n      const dirents = fs.readdirSync(dir, {\n        withFileTypes: true\n      });\n\n      for (const dirent of dirents) {\n        const fullpath = path.resolve(dir, dirent.name);\n\n        if (dirent.isDirectory()) {\n          yield* getFiles(fullpath);\n        } else {\n          yield {\n            fullpath: fullpath,\n            linuxfullpath: slash(fullpath),\n            relativepath: fullpath.split(\"public\" + envSlash)[1],\n            linuxpath: slash(fullpath.split(\"public\" + envSlash)[1]),\n            filename: dirent.name\n          };\n        }\n      }\n    }\n\n    (() => {\n      for (const f of getFiles('public/archive')) {\n        filesToAnalyze.push(f);\n      }\n    })(); //containerResult Promise starts pending\n\n\n    const containerResult = await new Promise((resolveContainer, rejectContainer) => {\n      try {\n        const analyzedFiles = [];\n        filesToAnalyze.forEach(async (fileObj, fileIndex) => {\n          const pdf = fileObj.fullpath.toLowerCase().includes(\".pdf\");\n          const docx = fileObj.fullpath.toLowerCase().includes(\".docx\");\n          const doc = fileObj.fullpath.toLowerCase().includes(\".doc\"); //singleResult Promise starts pending\n\n          const singleResult = await new Promise((resolveSingle, rejectSingle) => {\n            if (pdf) {\n              //[Pdf procedure] (PdfReader + manual array push)\n              const pdfBuffer = fs.readFileSync(fileObj.fullpath);\n\n              const getPdfContent = async () => {\n                const pdfContentArray = [];\n                await new PdfReader().parseFileItems(fileObj.fullpath, async (err, item) => {\n                  if (err) return rejectSingle(err); //rejecting singleResult Promise\n\n                  if (!item) {\n                    //Condizione d'uscita da parseFileItems()\n                    return resolveSingle({\n                      //resolving singleResult Promise\n                      fullpath: fileObj.fullpath,\n                      linuxfullpath: fileObj.linuxfullpath,\n                      filename: fileObj.filename,\n                      relativepath: fileObj.relativepath,\n                      linuxpath: fileObj.linuxpath,\n                      content: pdfContentArray.join(\" \")\n                    });\n                  }\n\n                  if (item.text) {\n                    //Per ogni frammento del pdf, pusho in pdfContentArray.\n                    pdfContentArray.push(item.text);\n                    return true;\n                  }\n                });\n              };\n\n              getPdfContent();\n            } else if (docx) {\n              //[Docx procedure] (mammoth)\n              const options = {};\n              mammoth.convertToHtml({\n                path: 'public' + envSlash + fileObj.relativepath\n              }, options).then(mammothResult => {\n                if (mammothResult.messages.length > 0) {\n                  for (let x; x < mammothResult.messages.length; x++) {\n                    console.log(\"\\n\\n Errors:\", mammothResult.messages[x], '\\n\\n');\n                  }\n                }\n\n                return resolveSingle({\n                  //resolving singleResult Promise\n                  fullpath: fileObj.fullpath,\n                  linuxfullpath: fileObj.linuxfullpath,\n                  filename: fileObj.filename,\n                  relativepath: fileObj.relativepath,\n                  linuxpath: fileObj.linuxpath,\n                  content: mammothResult.value\n                });\n              });\n            } else if (doc) {\n              //[Doc procedure] (WordExtractor)\n              const getDocContent = async fileObj => {\n                const docExtractor = new WordExtractor();\n                const extractedContent = await docExtractor.extract('public' + envSlash + fileObj.relativepath).then(function (doc) {\n                  resolveSingle({\n                    //resolving singleResult Promise\n                    fullpath: fileObj.fullpath,\n                    linuxfullpath: fileObj.linuxfullpath,\n                    filename: fileObj.filename,\n                    relativepath: fileObj.relativepath,\n                    linuxpath: fileObj.linuxpath,\n                    content: JSON.stringify(doc.getBody())\n                  });\n                });\n              };\n\n              getDocContent(fileObj);\n            } else {\n              rejectSingle(\"File is not pdf, docx or doc!\"); //rejecting singleResult Promise\n            }\n          }).then(singleResult => {\n            return singleResult;\n          }); //singleResult Promise resolved/rejected\n\n          await analyzedFiles.push({\n            fullpath: fileObj.fullpath,\n            filename: fileObj.filename,\n            relativepath: fileObj.relativepath,\n            linuxpath: fileObj.linuxpath,\n            content: singleResult.content\n          });\n\n          if (analyzedFiles.length === filesToAnalyze.length) {\n            //Qui dovrebbe salvare il json di containerResult\n            const mappedArchiveStr = JSON.stringify([...analyzedFiles]);\n            console.log(\"|||||||||||||||||||||||| started writing a json file representing the archive\");\n            const todayDate = new Date();\n            const todayUTC = todayDate.toUTCString();\n            const writeFileName = todayUTC.slice(0, 16);\n            await fs.writeFileSync(\"mappedArchive\" + envSlash + writeFileName + \".json\", mappedArchiveStr);\n            console.log(\"|||||||||||||||||||||||| finished writing json file\");\n            resolveContainer(analyzedFiles); //resolving containerResult Promise\n            //analyzedFiles is ready\n          } else {\n            console.log(\"(analyzedFiles.length !== filesToAnalyze.length) fileIndex attuale:\", fileIndex);\n          }\n        });\n      } catch (errContainer) {\n        console.log(\"rejectContainer with error:\", errContainer);\n        rejectContainer(errContainer); //rejecting containerResult Promise\n      }\n    }).then(async containerResult => {\n      dataToFilter.push(...containerResult);\n      return containerResult;\n    }); //containerResult Promise resolved/rejected\n  }\n\n  const filteredDocs = dataToFilter.filter(d => {\n    if (d.content) {\n      //Eventuali affinamenti del filtro andranno qui\n      const cleanContent = d.content.replace(/[^\\w\\s]/gi, '').toLowerCase();\n      return cleanContent.includes(searchterms.replace(/[^\\w\\s]/gi, '').toLowerCase());\n    } else {\n      return false;\n    }\n  });\n\n  const checkIfConversionNeeded = fileObjArr => {\n    const names = fileObjArr.map(el => el.filename);\n    return names.some(name => name.includes(\".docx\") || name.includes(\".doc\"));\n  };\n\n  if (checkIfConversionNeeded(filteredDocs)) {\n    let convertedDocs = [];\n    conversionFinished = false;\n\n    for (let x = 0; x < filteredDocs.length; x++) {\n      const d = filteredDocs[x];\n      const libreResult = await new Promise((resolveLibre, rejectLibre) => {\n        if (d && d.filename) {\n          const extend = '.pdf';\n          const enterPath = d.fullpath;\n          const outputPath = d.filename.includes(\".docx\") ? d.fullpath.split('.docx')[0] + extend : d.fullpath.split('.doc')[0] + extend;\n          const file = fs.readFileSync(enterPath);\n          libre.convert(file, extend, undefined, async (err, done) => {\n            if (err) {\n              console.log(`\\n\\n Error converting file: ${err} \\n\\n`);\n              rejectLibre(err);\n            } else {\n              // writeFileSync funziona, crea veramente il pdf, ma sarebbe troppo pesante farlo ogni volta per tutti i file, quindi mi limito a sfruttare il buffer: done.\n              //await fs.writeFileSync(outputPath, done)\n              resolveLibre(done);\n            }\n          });\n        } else {\n          console.log(\"Error - Caso inaspettato con questo file: \", filteredDocs[x]);\n        }\n      }).then(libreResult => {\n        return libreResult;\n      });\n      let mapResult = {};\n\n      if (libreResult && libreResult.byteLength) {\n        mapResult = {\n          fullpath: d.fullpath,\n          filename: d.filename,\n          relativepath: d.relativepath,\n          linuxpath: d.linuxpath,\n          content: d.filename.includes(\".docx\") ? d.content : \"\",\n          buffer: libreResult\n        };\n      } else {\n        mapResult = {\n          fullpath: d.fullpath,\n          filename: d.filename,\n          relativepath: d.relativepath,\n          linuxpath: d.linuxpath,\n          content: d.filename.includes(\".docx\") ? d.content : \"\"\n        };\n      }\n\n      const updateConvertedDocs = (convertedArr, originalArr) => {\n        const resultArr = [...convertedArr, mapResult];\n\n        if (resultArr.length === originalArr.length) {\n          conversionFinished = true;\n        }\n\n        return resultArr;\n      };\n\n      convertedDocs = await updateConvertedDocs(convertedDocs, filteredDocs);\n    }\n\n    (function forceWait() {\n      if (!conversionFinished) {\n        setTimeout(forceWait, 1000);\n      } else {\n        return res.status(200).json({\n          //Success - Trovato qualcosa per i searchterms immessi, e nessun errore.\n          success: true,\n          data: {\n            filteredDocs: convertedDocs\n          }\n        });\n      }\n    })();\n  } else {\n    return res.status(200).json({\n      //Success - Trovato qualcosa per i searchterms immessi, e nessun errore.\n      success: true,\n      data: {\n        filteredDocs: filteredDocs\n      }\n    });\n  }\n});","map":null,"metadata":{},"sourceType":"module"}