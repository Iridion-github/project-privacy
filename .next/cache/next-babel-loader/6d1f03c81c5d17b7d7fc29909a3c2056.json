{"ast":null,"code":"import path from 'path';\nimport slash from 'slash';\nimport { PdfReader } from \"pdfreader\"; //pacchetto usato per leggere i pdf \n\nimport fs from 'fs'; //pacchetto usato per leggere docx files\n\nimport mammoth from 'mammoth'; //pacchetto usato per convertire i docx in html\n\nimport WordExtractor from \"word-extractor\"; //pacchetto usato per leggere i doc files\n//import libre from 'libreoffice-convert-win' //pacchetto usato per convertire i docx files in pdf (windows version)\n\nimport libre from 'libreoffice-convert'; //pacchetto usato per convertire i docx files in pdf (linux version)\n\nconst environment = \"linux\";\nconst envSlash = environment === \"windows\" ? \"\\\\\" : \"/\"; // ----------------------------- [Responds with an Object for every document in Archive] -----------------------------    \n\nexport default (async (req, res) => {\n  let conversionFinished = true;\n  let isArchiveMapped; //variabile bool che ci dirà se c'è una versione di oggi dell'archivio mappato\n\n  let mappedArchive; //variabile array dei dati dell'archivio mappato\n\n  console.log(\"BACKEND - advancedSearch req.query:\", req.query);\n  const searchterms = req.query.searchterms && req.query.searchterms.length > 0 ? req.query.searchterms : null;\n  const activeFilters = JSON.parse(req.query.activeFilters);\n  const filesToAnalyze = [];\n  const dataToFilter = [];\n  const todayDate = new Date();\n  const todayUTC = todayDate.toUTCString();\n  const readFileName = todayUTC.slice(0, 16);\n\n  try {\n    const mappedArchiveRaw = await fs.readFileSync(\"mappedArchive\" + envSlash + readFileName + \".json\");\n    mappedArchive = JSON.parse(mappedArchiveRaw);\n    isArchiveMapped = true;\n    dataToFilter.push(...mappedArchive);\n  } catch (mappedArchiveMissing) {\n    console.log(mappedArchiveMissing);\n    isArchiveMapped = false;\n  }\n\n  if (!isArchiveMapped) {\n    //funzione che estrae i path precisi di ogni file all'interno della dir archive\n    function* getFiles(dir) {\n      const dirents = fs.readdirSync(dir, {\n        withFileTypes: true\n      });\n\n      for (const dirent of dirents) {\n        const fullpath = path.resolve(dir, dirent.name);\n\n        if (dirent.isDirectory()) {\n          yield* getFiles(fullpath);\n        } else {\n          yield {\n            fullpath: fullpath,\n            linuxfullpath: slash(fullpath),\n            relativepath: fullpath.split(\"public\", envSlash)[1],\n            linuxpath: slash(fullpath.split(\"public\" + envSlash)[1]),\n            filename: dirent.name\n          };\n        }\n      }\n    }\n\n    (() => {\n      for (const f of getFiles('public/archive')) {\n        filesToAnalyze.push(f);\n      }\n    })(); //containerResult Promise starts pending\n\n\n    const containerResult = await new Promise((resolveContainer, rejectContainer) => {\n      try {\n        const analyzedFiles = [];\n        filesToAnalyze.forEach(async (fileObj, fileIndex) => {\n          const pdf = fileObj.fullpath.toLowerCase().includes(\".pdf\");\n          const docx = fileObj.fullpath.toLowerCase().includes(\".docx\");\n          const doc = fileObj.fullpath.toLowerCase().includes(\".doc\"); //singleResult Promise starts pending\n\n          const singleResult = await new Promise((resolveSingle, rejectSingle) => {\n            if (pdf) {\n              //[Pdf procedure] (PdfReader + manual array push)\n              if (!activeFilters.includePdf) resolveSingle({});\n              const pdfBuffer = fs.readFileSync(fileObj.fullpath);\n\n              const getPdfContent = async () => {\n                const pdfContentArray = [];\n                await new PdfReader().parseFileItems(fileObj.fullpath, async (err, item) => {\n                  if (err) return rejectSingle(err); //rejecting singleResult Promise\n\n                  if (!item) {\n                    //Condizione d'uscita da parseFileItems()\n                    return resolveSingle({\n                      //resolving singleResult Promise\n                      fullpath: fileObj.fullpath,\n                      linuxfullpath: fileObj.linuxfullpath,\n                      filename: fileObj.filename,\n                      relativepath: fileObj.relativepath,\n                      linuxpath: fileObj.linuxpath,\n                      content: pdfContentArray.join(\" \")\n                    });\n                  }\n\n                  if (item.text) {\n                    //Per ogni frammento del pdf, pusho in pdfContentArray.\n                    pdfContentArray.push(item.text);\n                    return true;\n                  }\n                });\n              };\n\n              getPdfContent();\n            } else if (docx) {\n              if (!activeFilters.includeDocx) resolveSingle({}); //[Docx procedure] (mammoth)\n\n              const options = {};\n              mammoth.convertToHtml({\n                path: 'public' + envSlash + fileObj.relativepath\n              }, options).then(mammothResult => {\n                if (mammothResult.messages.length > 0) {\n                  for (let x; x < mammothResult.messages.length; x++) {\n                    console.log(\"\\n\\n Errors:\", mammothResult.messages[x], '\\n\\n');\n                  }\n                }\n\n                return resolveSingle({\n                  //resolving singleResult Promise\n                  fullpath: fileObj.fullpath,\n                  linuxfullpath: fileObj.linuxfullpath,\n                  filename: fileObj.filename,\n                  relativepath: fileObj.relativepath,\n                  linuxpath: fileObj.linuxpath,\n                  content: mammothResult.value\n                });\n              });\n            } else if (doc) {\n              if (!activeFilters.includeDoc) resolveSingle({}); //[Doc procedure] (WordExtractor)\n\n              const getDocContent = async fileObj => {\n                const docExtractor = new WordExtractor();\n                const extractedContent = await docExtractor.extract('public' + envSlash + fileObj.relativepath).then(function (doc) {\n                  resolveSingle({\n                    //resolving singleResult Promise\n                    fullpath: fileObj.fullpath,\n                    linuxfullpath: fileObj.linuxfullpath,\n                    filename: fileObj.filename,\n                    relativepath: fileObj.relativepath,\n                    linuxpath: fileObj.linuxpath,\n                    content: JSON.stringify(doc.getBody())\n                  });\n                });\n              };\n\n              getDocContent(fileObj);\n            } else {\n              rejectSingle(\"File is not pdf, docx or doc!\"); //rejecting singleResult Promise\n            }\n          }).then(singleResult => {\n            return singleResult;\n          }); //singleResult Promise resolved/rejected\n\n          await analyzedFiles.push({\n            fullpath: fileObj.fullpath,\n            filename: fileObj.filename,\n            relativepath: fileObj.relativepath,\n            linuxpath: fileObj.linuxpath,\n            content: singleResult && singleResult.content ? singleResult.content : \"\"\n          });\n\n          if (analyzedFiles.length === filesToAnalyze.length) {\n            //Qui dovrebbe salvare il json di containerResult\n            const mappedArchiveStr = JSON.stringify([...analyzedFiles]);\n            console.log(\"|||||||||||||||||||||||| started writing a json file representing the archive\");\n            const todayDate = new Date();\n            const todayUTC = todayDate.toUTCString();\n            const writeFileName = todayUTC.slice(0, 16);\n            await fs.writeFileSync(\"mappedArchive\" + envSlash + writeFileName + \".json\", mappedArchiveStr);\n            console.log(\"|||||||||||||||||||||||| finished writing json file\");\n            resolveContainer(analyzedFiles); //resolving containerResult Promise\n          } else {\n            console.log(\"(analyzedFiles.length !== filesToAnalyze.length) fileIndex attuale:\", fileIndex);\n          }\n        });\n      } catch (errContainer) {\n        console.log(\"rejectContainer with error:\", errContainer);\n        rejectContainer(errContainer); //rejecting containerResult Promise\n      }\n    }).then(containerResult => {\n      return containerResult;\n    }); //containerResult Promise resolved/rejected\n  }\n\n  const filteredDocs = dataToFilter.filter(d => {\n    if (d.content) {\n      if (!activeFilters.includePdf && d.filename.includes(\".pdf\")) return false;\n      if (!activeFilters.includeDocx && d.filename.includes(\".docx\")) return false;\n      if (!activeFilters.includeDoc && d.filename.includes(\".doc\") && d.filename.split(\".doc\")[1].length === 0) return false; //Eventuali affinamenti del filtro andranno qui \n\n      const cleanContent = d.content.replace(/[^\\w\\s]/gi, '').toLowerCase();\n      let result = null;\n\n      if (activeFilters.indCorteCost) {\n        let target = \".ind corte\".replace(/[^\\w\\s]/gi, '');\n        result = cleanContent.includes(target);\n      } else {\n        result = cleanContent.includes(searchterms.replace(/[^\\w\\s]/gi, '').toLowerCase());\n      }\n\n      return result;\n    } else {\n      return false;\n    }\n  });\n\n  const checkIfConversionNeeded = fileObjArr => {\n    const names = fileObjArr.map(el => el.filename);\n    return names.some(name => name.includes(\".docx\") || name.includes(\".doc\"));\n  };\n\n  if (checkIfConversionNeeded(filteredDocs)) {\n    let convertedDocs = [];\n    conversionFinished = false;\n\n    for (let x = 0; x < filteredDocs.length; x++) {\n      const d = filteredDocs[x];\n      const libreResult = await new Promise((resolveLibre, rejectLibre) => {\n        if (d && d.filename) {\n          const extend = '.pdf';\n          const enterPath = d.fullpath;\n          const outputPath = d.filename.includes(\".docx\") ? d.fullpath.split('.docx')[0] + extend : d.fullpath.split('.doc')[0] + extend;\n          const file = fs.readFileSync(enterPath);\n          libre.convert(file, extend, undefined, async (err, done) => {\n            if (err) {\n              console.log(`\\n\\n Error converting file: ${err} \\n\\n`);\n              rejectLibre(err);\n            } else {\n              // writeFileSync funziona, crea veramente il pdf, ma sarebbe troppo pesante farlo ogni volta per tutti i file, quindi mi limito a sfruttare il buffer: done.\n              //await fs.writeFileSync(outputPath, done)\n              resolveLibre(done);\n            }\n          });\n        } else {\n          console.log(\"Error - Caso inaspettato con questo file: \", filteredDocs[x]);\n        }\n      }).then(libreResult => {\n        return libreResult;\n      });\n      let mapResult = {};\n\n      if (libreResult && libreResult.byteLength) {\n        mapResult = {\n          fullpath: d.fullpath,\n          filename: d.filename,\n          relativepath: d.relativepath,\n          linuxpath: d.linuxpath,\n          content: d.filename.includes(\".docx\") ? d.content : \"\",\n          buffer: libreResult\n        };\n      } else {\n        mapResult = {\n          fullpath: d.fullpath,\n          filename: d.filename,\n          relativepath: d.relativepath,\n          linuxpath: d.linuxpath,\n          content: d.filename.includes(\".docx\") ? d.content : \"\"\n        };\n      }\n\n      const updateConvertedDocs = (convertedArr, originalArr) => {\n        const resultArr = [...convertedArr, mapResult];\n\n        if (resultArr.length === originalArr.length) {\n          conversionFinished = true;\n        }\n\n        return resultArr;\n      };\n\n      convertedDocs = await updateConvertedDocs(convertedDocs, filteredDocs);\n    }\n\n    (function forceWait() {\n      if (!conversionFinished) {\n        setTimeout(forceWait, 1000);\n      } else {\n        return res.status(200).json({\n          //Success - Trovato qualcosa per i searchterms immessi, e nessun errore.\n          success: true,\n          data: {\n            filteredDocs: convertedDocs\n          }\n        });\n      }\n    })();\n  } else {\n    return res.status(200).json({\n      //Success - Trovato qualcosa per i searchterms immessi, e nessun errore.\n      success: true,\n      data: {\n        filteredDocs: filteredDocs\n      }\n    });\n  }\n});","map":{"version":3,"sources":["/home/iridion/Desktop/Repos/Freelancer/project-privacy/pages/api/archive/advancedSearch.js"],"names":["path","slash","PdfReader","fs","mammoth","WordExtractor","libre","environment","envSlash","req","res","conversionFinished","isArchiveMapped","mappedArchive","console","log","query","searchterms","length","activeFilters","JSON","parse","filesToAnalyze","dataToFilter","todayDate","Date","todayUTC","toUTCString","readFileName","slice","mappedArchiveRaw","readFileSync","push","mappedArchiveMissing","getFiles","dir","dirents","readdirSync","withFileTypes","dirent","fullpath","resolve","name","isDirectory","linuxfullpath","relativepath","split","linuxpath","filename","f","containerResult","Promise","resolveContainer","rejectContainer","analyzedFiles","forEach","fileObj","fileIndex","pdf","toLowerCase","includes","docx","doc","singleResult","resolveSingle","rejectSingle","includePdf","pdfBuffer","getPdfContent","pdfContentArray","parseFileItems","err","item","content","join","text","includeDocx","options","convertToHtml","then","mammothResult","messages","x","value","includeDoc","getDocContent","docExtractor","extractedContent","extract","stringify","getBody","mappedArchiveStr","writeFileName","writeFileSync","errContainer","filteredDocs","filter","d","cleanContent","replace","result","indCorteCost","target","checkIfConversionNeeded","fileObjArr","names","map","el","some","convertedDocs","libreResult","resolveLibre","rejectLibre","extend","enterPath","outputPath","file","convert","undefined","done","mapResult","byteLength","buffer","updateConvertedDocs","convertedArr","originalArr","resultArr","forceWait","setTimeout","status","json","success","data"],"mappings":"AAAA,OAAOA,IAAP,MAAiB,MAAjB;AACA,OAAOC,KAAP,MAAkB,OAAlB;AACA,SAASC,SAAT,QAA0B,WAA1B,C,CAAuC;;AACvC,OAAOC,EAAP,MAAe,IAAf,C,CAAmB;;AACnB,OAAOC,OAAP,MAAoB,SAApB,C,CAA8B;;AAC9B,OAAOC,aAAP,MAA0B,gBAA1B,C,CAA2C;AAC3C;;AACA,OAAOC,KAAP,MAAkB,qBAAlB,C,CAAwC;;AAExC,MAAMC,WAAW,GAAG,OAApB;AAEA,MAAMC,QAAQ,GAAID,WAAW,KAAK,SAAjB,GAA8B,IAA9B,GAAqC,GAAtD,C,CAEA;;AAEA,gBAAe,OAAOE,GAAP,EAAYC,GAAZ,KAAoB;AACjC,MAAIC,kBAAkB,GAAG,IAAzB;AACA,MAAIC,eAAJ,CAFiC,CAEb;;AACpB,MAAIC,aAAJ,CAHiC,CAGf;;AAClBC,EAAAA,OAAO,CAACC,GAAR,CAAY,qCAAZ,EAAmDN,GAAG,CAACO,KAAvD;AACA,QAAMC,WAAW,GAAGR,GAAG,CAACO,KAAJ,CAAUC,WAAV,IAAyBR,GAAG,CAACO,KAAJ,CAAUC,WAAV,CAAsBC,MAAtB,GAA+B,CAAxD,GAA4DT,GAAG,CAACO,KAAJ,CAAUC,WAAtE,GAAoF,IAAxG;AACA,QAAME,aAAa,GAAGC,IAAI,CAACC,KAAL,CAAWZ,GAAG,CAACO,KAAJ,CAAUG,aAArB,CAAtB;AACA,QAAMG,cAAc,GAAG,EAAvB;AACA,QAAMC,YAAY,GAAG,EAArB;AACA,QAAMC,SAAS,GAAG,IAAIC,IAAJ,EAAlB;AACA,QAAMC,QAAQ,GAAGF,SAAS,CAACG,WAAV,EAAjB;AACA,QAAMC,YAAY,GAAGF,QAAQ,CAACG,KAAT,CAAe,CAAf,EAAkB,EAAlB,CAArB;;AACA,MAAI;AACF,UAAMC,gBAAgB,GAAG,MAAM3B,EAAE,CAAC4B,YAAH,CAAgB,kBAAkBvB,QAAlB,GAA6BoB,YAA7B,GAA4C,OAA5D,CAA/B;AACAf,IAAAA,aAAa,GAAGO,IAAI,CAACC,KAAL,CAAWS,gBAAX,CAAhB;AACAlB,IAAAA,eAAe,GAAG,IAAlB;AACAW,IAAAA,YAAY,CAACS,IAAb,CAAkB,GAAGnB,aAArB;AACD,GALD,CAKE,OAAOoB,oBAAP,EAA6B;AAC7BnB,IAAAA,OAAO,CAACC,GAAR,CAAYkB,oBAAZ;AACArB,IAAAA,eAAe,GAAG,KAAlB;AACD;;AAED,MAAI,CAACA,eAAL,EAAsB;AACpB;AACA,cAAUsB,QAAV,CAAmBC,GAAnB,EAAwB;AACtB,YAAMC,OAAO,GAAGjC,EAAE,CAACkC,WAAH,CAAeF,GAAf,EAAoB;AAAEG,QAAAA,aAAa,EAAE;AAAjB,OAApB,CAAhB;;AACA,WAAK,MAAMC,MAAX,IAAqBH,OAArB,EAA8B;AAC5B,cAAMI,QAAQ,GAAGxC,IAAI,CAACyC,OAAL,CAAaN,GAAb,EAAkBI,MAAM,CAACG,IAAzB,CAAjB;;AACA,YAAIH,MAAM,CAACI,WAAP,EAAJ,EAA0B;AACxB,iBAAOT,QAAQ,CAACM,QAAD,CAAf;AACD,SAFD,MAEO;AACL,gBAAM;AACJA,YAAAA,QAAQ,EAAEA,QADN;AAEJI,YAAAA,aAAa,EAAE3C,KAAK,CAACuC,QAAD,CAFhB;AAGJK,YAAAA,YAAY,EAAEL,QAAQ,CAACM,KAAT,CAAe,QAAf,EAAyBtC,QAAzB,EAAmC,CAAnC,CAHV;AAIJuC,YAAAA,SAAS,EAAE9C,KAAK,CAACuC,QAAQ,CAACM,KAAT,CAAe,WAAWtC,QAA1B,EAAoC,CAApC,CAAD,CAJZ;AAKJwC,YAAAA,QAAQ,EAAET,MAAM,CAACG;AALb,WAAN;AAOD;AACF;AACF;;AACD,KAAC,MAAM;AACL,WAAK,MAAMO,CAAX,IAAgBf,QAAQ,CAAC,gBAAD,CAAxB,EAA4C;AAC1CZ,QAAAA,cAAc,CAACU,IAAf,CAAoBiB,CAApB;AACD;AACF,KAJD,IAnBoB,CAyBpB;;;AACA,UAAMC,eAAe,GAAG,MAAM,IAAIC,OAAJ,CAAY,CAACC,gBAAD,EAAmBC,eAAnB,KAAuC;AAC/E,UAAI;AACF,cAAMC,aAAa,GAAG,EAAtB;AACAhC,QAAAA,cAAc,CAACiC,OAAf,CAAuB,OAAOC,OAAP,EAAgBC,SAAhB,KAA8B;AACnD,gBAAMC,GAAG,GAAGF,OAAO,CAAChB,QAAR,CAAiBmB,WAAjB,GAA+BC,QAA/B,CAAwC,MAAxC,CAAZ;AACA,gBAAMC,IAAI,GAAGL,OAAO,CAAChB,QAAR,CAAiBmB,WAAjB,GAA+BC,QAA/B,CAAwC,OAAxC,CAAb;AACA,gBAAME,GAAG,GAAGN,OAAO,CAAChB,QAAR,CAAiBmB,WAAjB,GAA+BC,QAA/B,CAAwC,MAAxC,CAAZ,CAHmD,CAKnD;;AACA,gBAAMG,YAAY,GAAG,MAAM,IAAIZ,OAAJ,CAAY,CAACa,aAAD,EAAgBC,YAAhB,KAAiC;AACtE,gBAAIP,GAAJ,EAAS;AAAE;AACT,kBAAI,CAACvC,aAAa,CAAC+C,UAAnB,EAA+BF,aAAa,CAAC,EAAD,CAAb;AAC/B,oBAAMG,SAAS,GAAGhE,EAAE,CAAC4B,YAAH,CAAgByB,OAAO,CAAChB,QAAxB,CAAlB;;AACA,oBAAM4B,aAAa,GAAG,YAAY;AAChC,sBAAMC,eAAe,GAAG,EAAxB;AACA,sBAAM,IAAInE,SAAJ,GAAgBoE,cAAhB,CAA+Bd,OAAO,CAAChB,QAAvC,EAAiD,OAAO+B,GAAP,EAAYC,IAAZ,KAAqB;AAC1E,sBAAID,GAAJ,EAAS,OAAON,YAAY,CAACM,GAAD,CAAnB,CADiE,CACxC;;AAClC,sBAAI,CAACC,IAAL,EAAW;AAAE;AACX,2BAAOR,aAAa,CAAC;AAAE;AACrBxB,sBAAAA,QAAQ,EAAEgB,OAAO,CAAChB,QADC;AAEnBI,sBAAAA,aAAa,EAAEY,OAAO,CAACZ,aAFJ;AAGnBI,sBAAAA,QAAQ,EAAEQ,OAAO,CAACR,QAHC;AAInBH,sBAAAA,YAAY,EAAEW,OAAO,CAACX,YAJH;AAKnBE,sBAAAA,SAAS,EAAES,OAAO,CAACT,SALA;AAMnB0B,sBAAAA,OAAO,EAAEJ,eAAe,CAACK,IAAhB,CAAqB,GAArB;AANU,qBAAD,CAApB;AAQD;;AACD,sBAAIF,IAAI,CAACG,IAAT,EAAe;AAAE;AACfN,oBAAAA,eAAe,CAACrC,IAAhB,CAAqBwC,IAAI,CAACG,IAA1B;AACA,2BAAO,IAAP;AACD;AACF,iBAhBK,CAAN;AAiBD,eAnBD;;AAoBAP,cAAAA,aAAa;AACd,aAxBD,MAwBO,IAAIP,IAAJ,EAAU;AACf,kBAAI,CAAC1C,aAAa,CAACyD,WAAnB,EAAgCZ,aAAa,CAAC,EAAD,CAAb,CADjB,CAEf;;AACA,oBAAMa,OAAO,GAAG,EAAhB;AACAzE,cAAAA,OAAO,CAAC0E,aAAR,CAAsB;AAAE9E,gBAAAA,IAAI,EAAE,WAAWQ,QAAX,GAAsBgD,OAAO,CAACX;AAAtC,eAAtB,EAA4EgC,OAA5E,EAAqFE,IAArF,CAA2FC,aAAD,IAAmB;AAC3G,oBAAIA,aAAa,CAACC,QAAd,CAAuB/D,MAAvB,GAAgC,CAApC,EAAuC;AACrC,uBAAK,IAAIgE,CAAT,EAAYA,CAAC,GAAGF,aAAa,CAACC,QAAd,CAAuB/D,MAAvC,EAA+CgE,CAAC,EAAhD,EAAoD;AAClDpE,oBAAAA,OAAO,CAACC,GAAR,CAAY,cAAZ,EAA4BiE,aAAa,CAACC,QAAd,CAAuBC,CAAvB,CAA5B,EAAuD,MAAvD;AACD;AACF;;AACD,uBAAOlB,aAAa,CAAC;AAAE;AACrBxB,kBAAAA,QAAQ,EAAEgB,OAAO,CAAChB,QADC;AAEnBI,kBAAAA,aAAa,EAAEY,OAAO,CAACZ,aAFJ;AAGnBI,kBAAAA,QAAQ,EAAEQ,OAAO,CAACR,QAHC;AAInBH,kBAAAA,YAAY,EAAEW,OAAO,CAACX,YAJH;AAKnBE,kBAAAA,SAAS,EAAES,OAAO,CAACT,SALA;AAMnB0B,kBAAAA,OAAO,EAAEO,aAAa,CAACG;AANJ,iBAAD,CAApB;AAQD,eAdD;AAeD,aAnBM,MAmBA,IAAIrB,GAAJ,EAAS;AACd,kBAAI,CAAC3C,aAAa,CAACiE,UAAnB,EAA+BpB,aAAa,CAAC,EAAD,CAAb,CADjB,CAEd;;AACA,oBAAMqB,aAAa,GAAG,MAAO7B,OAAP,IAAmB;AACvC,sBAAM8B,YAAY,GAAG,IAAIjF,aAAJ,EAArB;AACA,sBAAMkF,gBAAgB,GAAG,MAAMD,YAAY,CAACE,OAAb,CAAqB,WAAWhF,QAAX,GAAsBgD,OAAO,CAACX,YAAnD,EAAiEkC,IAAjE,CAAsE,UAAUjB,GAAV,EAAe;AAClHE,kBAAAA,aAAa,CAAC;AAAE;AACdxB,oBAAAA,QAAQ,EAAEgB,OAAO,CAAChB,QADN;AAEZI,oBAAAA,aAAa,EAAEY,OAAO,CAACZ,aAFX;AAGZI,oBAAAA,QAAQ,EAAEQ,OAAO,CAACR,QAHN;AAIZH,oBAAAA,YAAY,EAAEW,OAAO,CAACX,YAJV;AAKZE,oBAAAA,SAAS,EAAES,OAAO,CAACT,SALP;AAMZ0B,oBAAAA,OAAO,EAAErD,IAAI,CAACqE,SAAL,CAAe3B,GAAG,CAAC4B,OAAJ,EAAf;AANG,mBAAD,CAAb;AAQD,iBAT8B,CAA/B;AAUD,eAZD;;AAaAL,cAAAA,aAAa,CAAC7B,OAAD,CAAb;AACD,aAjBM,MAiBA;AACLS,cAAAA,YAAY,CAAC,+BAAD,CAAZ,CADK,CACyC;AAC/C;AACF,WAhE0B,EAgExBc,IAhEwB,CAgEnBhB,YAAY,IAAI;AACtB,mBAAOA,YAAP;AACD,WAlE0B,CAA3B,CANmD,CAyEnD;;AAEA,gBAAMT,aAAa,CAACtB,IAAd,CAAmB;AACvBQ,YAAAA,QAAQ,EAAEgB,OAAO,CAAChB,QADK;AAEvBQ,YAAAA,QAAQ,EAAEQ,OAAO,CAACR,QAFK;AAGvBH,YAAAA,YAAY,EAAEW,OAAO,CAACX,YAHC;AAIvBE,YAAAA,SAAS,EAAES,OAAO,CAACT,SAJI;AAKvB0B,YAAAA,OAAO,EAAGV,YAAY,IAAIA,YAAY,CAACU,OAA9B,GAAyCV,YAAY,CAACU,OAAtD,GAAgE;AALlD,WAAnB,CAAN;;AAQA,cAAInB,aAAa,CAACpC,MAAd,KAAyBI,cAAc,CAACJ,MAA5C,EAAoD;AAClD;AACA,kBAAMyE,gBAAgB,GAAGvE,IAAI,CAACqE,SAAL,CAAe,CAAC,GAAGnC,aAAJ,CAAf,CAAzB;AACAxC,YAAAA,OAAO,CAACC,GAAR,CAAY,+EAAZ;AACA,kBAAMS,SAAS,GAAG,IAAIC,IAAJ,EAAlB;AACA,kBAAMC,QAAQ,GAAGF,SAAS,CAACG,WAAV,EAAjB;AACA,kBAAMiE,aAAa,GAAGlE,QAAQ,CAACG,KAAT,CAAe,CAAf,EAAkB,EAAlB,CAAtB;AACA,kBAAM1B,EAAE,CAAC0F,aAAH,CAAiB,kBAAkBrF,QAAlB,GAA6BoF,aAA7B,GAA6C,OAA9D,EAAuED,gBAAvE,CAAN;AACA7E,YAAAA,OAAO,CAACC,GAAR,CAAY,qDAAZ;AACAqC,YAAAA,gBAAgB,CAACE,aAAD,CAAhB,CATkD,CASlB;AACjC,WAVD,MAUO;AACLxC,YAAAA,OAAO,CAACC,GAAR,CAAY,qEAAZ,EAAmF0C,SAAnF;AACD;AACF,SAhGD;AAiGD,OAnGD,CAmGE,OAAOqC,YAAP,EAAqB;AACrBhF,QAAAA,OAAO,CAACC,GAAR,CAAY,6BAAZ,EAA2C+E,YAA3C;AACAzC,QAAAA,eAAe,CAACyC,YAAD,CAAf,CAFqB,CAES;AAC/B;AACF,KAxG6B,EAwG3Bf,IAxG2B,CAwGrB7B,eAAD,IAAqB;AAC3B,aAAOA,eAAP;AACD,KA1G6B,CAA9B,CA1BoB,CAoIlB;AACH;;AAED,QAAM6C,YAAY,GAAGxE,YAAY,CAACyE,MAAb,CAAoBC,CAAC,IAAI;AAC5C,QAAIA,CAAC,CAACxB,OAAN,EAAe;AACb,UAAI,CAACtD,aAAa,CAAC+C,UAAf,IAA6B+B,CAAC,CAACjD,QAAF,CAAWY,QAAX,CAAoB,MAApB,CAAjC,EAA8D,OAAO,KAAP;AAC9D,UAAI,CAACzC,aAAa,CAACyD,WAAf,IAA8BqB,CAAC,CAACjD,QAAF,CAAWY,QAAX,CAAoB,OAApB,CAAlC,EAAgE,OAAO,KAAP;AAChE,UAAI,CAACzC,aAAa,CAACiE,UAAf,IAA6Ba,CAAC,CAACjD,QAAF,CAAWY,QAAX,CAAoB,MAApB,CAA7B,IAA4DqC,CAAC,CAACjD,QAAF,CAAWF,KAAX,CAAiB,MAAjB,EAAyB,CAAzB,EAA4B5B,MAA5B,KAAuC,CAAvG,EAA0G,OAAO,KAAP,CAH7F,CAIb;;AACA,YAAMgF,YAAY,GAAGD,CAAC,CAACxB,OAAF,CAAU0B,OAAV,CAAkB,WAAlB,EAA+B,EAA/B,EAAmCxC,WAAnC,EAArB;AACA,UAAIyC,MAAM,GAAG,IAAb;;AACA,UAAIjF,aAAa,CAACkF,YAAlB,EAAgC;AAC9B,YAAIC,MAAM,GAAG,aAAaH,OAAb,CAAqB,WAArB,EAAkC,EAAlC,CAAb;AACAC,QAAAA,MAAM,GAAGF,YAAY,CAACtC,QAAb,CAAsB0C,MAAtB,CAAT;AACD,OAHD,MAGO;AACLF,QAAAA,MAAM,GAAGF,YAAY,CAACtC,QAAb,CAAsB3C,WAAW,CAACkF,OAAZ,CAAoB,WAApB,EAAiC,EAAjC,EAAqCxC,WAArC,EAAtB,CAAT;AACD;;AACD,aAAOyC,MAAP;AACD,KAdD,MAcO;AACL,aAAO,KAAP;AACD;AACF,GAlBoB,CAArB;;AAoBA,QAAMG,uBAAuB,GAAIC,UAAD,IAAgB;AAC9C,UAAMC,KAAK,GAAGD,UAAU,CAACE,GAAX,CAAeC,EAAE,IAAIA,EAAE,CAAC3D,QAAxB,CAAd;AACA,WAAOyD,KAAK,CAACG,IAAN,CAAWlE,IAAI,IAAKA,IAAI,CAACkB,QAAL,CAAc,OAAd,KAA0BlB,IAAI,CAACkB,QAAL,CAAc,MAAd,CAA9C,CAAP;AACD,GAHD;;AAKA,MAAI2C,uBAAuB,CAACR,YAAD,CAA3B,EAA2C;AACzC,QAAIc,aAAa,GAAG,EAApB;AACAlG,IAAAA,kBAAkB,GAAG,KAArB;;AAEA,SAAK,IAAIuE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGa,YAAY,CAAC7E,MAAjC,EAAyCgE,CAAC,EAA1C,EAA8C;AAC5C,YAAMe,CAAC,GAAGF,YAAY,CAACb,CAAD,CAAtB;AACA,YAAM4B,WAAW,GAAG,MAAM,IAAI3D,OAAJ,CAAY,CAAC4D,YAAD,EAAeC,WAAf,KAA+B;AACnE,YAAIf,CAAC,IAAIA,CAAC,CAACjD,QAAX,EAAqB;AACnB,gBAAMiE,MAAM,GAAG,MAAf;AACA,gBAAMC,SAAS,GAAGjB,CAAC,CAACzD,QAApB;AACA,gBAAM2E,UAAU,GAAGlB,CAAC,CAACjD,QAAF,CAAWY,QAAX,CAAoB,OAApB,IAA+BqC,CAAC,CAACzD,QAAF,CAAWM,KAAX,CAAiB,OAAjB,EAA0B,CAA1B,IAA+BmE,MAA9D,GAAuEhB,CAAC,CAACzD,QAAF,CAAWM,KAAX,CAAiB,MAAjB,EAAyB,CAAzB,IAA8BmE,MAAxH;AACA,gBAAMG,IAAI,GAAGjH,EAAE,CAAC4B,YAAH,CAAgBmF,SAAhB,CAAb;AACA5G,UAAAA,KAAK,CAAC+G,OAAN,CAAcD,IAAd,EAAoBH,MAApB,EAA4BK,SAA5B,EAAuC,OAAO/C,GAAP,EAAYgD,IAAZ,KAAqB;AAC1D,gBAAIhD,GAAJ,EAAS;AACPzD,cAAAA,OAAO,CAACC,GAAR,CAAa,+BAA8BwD,GAAI,OAA/C;AACAyC,cAAAA,WAAW,CAACzC,GAAD,CAAX;AACD,aAHD,MAGO;AACL;AACA;AACAwC,cAAAA,YAAY,CAACQ,IAAD,CAAZ;AACD;AACF,WATD;AAUD,SAfD,MAeO;AACLzG,UAAAA,OAAO,CAACC,GAAR,CAAY,4CAAZ,EAA0DgF,YAAY,CAACb,CAAD,CAAtE;AACD;AACF,OAnByB,EAmBvBH,IAnBuB,CAmBlB+B,WAAW,IAAI;AACrB,eAAOA,WAAP;AACD,OArByB,CAA1B;AAuBA,UAAIU,SAAS,GAAG,EAAhB;;AAEA,UAAIV,WAAW,IAAIA,WAAW,CAACW,UAA/B,EAA2C;AACzCD,QAAAA,SAAS,GAAG;AACVhF,UAAAA,QAAQ,EAAEyD,CAAC,CAACzD,QADF;AAEVQ,UAAAA,QAAQ,EAAEiD,CAAC,CAACjD,QAFF;AAGVH,UAAAA,YAAY,EAAEoD,CAAC,CAACpD,YAHN;AAIVE,UAAAA,SAAS,EAAEkD,CAAC,CAAClD,SAJH;AAKV0B,UAAAA,OAAO,EAAEwB,CAAC,CAACjD,QAAF,CAAWY,QAAX,CAAoB,OAApB,IAA+BqC,CAAC,CAACxB,OAAjC,GAA2C,EAL1C;AAMViD,UAAAA,MAAM,EAAEZ;AANE,SAAZ;AAQD,OATD,MASO;AACLU,QAAAA,SAAS,GAAG;AACVhF,UAAAA,QAAQ,EAAEyD,CAAC,CAACzD,QADF;AAEVQ,UAAAA,QAAQ,EAAEiD,CAAC,CAACjD,QAFF;AAGVH,UAAAA,YAAY,EAAEoD,CAAC,CAACpD,YAHN;AAIVE,UAAAA,SAAS,EAAEkD,CAAC,CAAClD,SAJH;AAKV0B,UAAAA,OAAO,EAAEwB,CAAC,CAACjD,QAAF,CAAWY,QAAX,CAAoB,OAApB,IAA+BqC,CAAC,CAACxB,OAAjC,GAA2C;AAL1C,SAAZ;AAOD;;AAED,YAAMkD,mBAAmB,GAAG,CAACC,YAAD,EAAeC,WAAf,KAA+B;AACzD,cAAMC,SAAS,GAAG,CAAC,GAAGF,YAAJ,EAAkBJ,SAAlB,CAAlB;;AACA,YAAIM,SAAS,CAAC5G,MAAV,KAAqB2G,WAAW,CAAC3G,MAArC,EAA6C;AAC3CP,UAAAA,kBAAkB,GAAG,IAArB;AACD;;AACD,eAAOmH,SAAP;AACD,OAND;;AAOAjB,MAAAA,aAAa,GAAG,MAAMc,mBAAmB,CAACd,aAAD,EAAgBd,YAAhB,CAAzC;AACD;;AAED,KAAC,SAASgC,SAAT,GAAqB;AACpB,UAAI,CAACpH,kBAAL,EAAyB;AACvBqH,QAAAA,UAAU,CAACD,SAAD,EAAY,IAAZ,CAAV;AACD,OAFD,MAEO;AACL,eAAOrH,GAAG,CAACuH,MAAJ,CAAW,GAAX,EAAgBC,IAAhB,CAAqB;AAAE;AAC5BC,UAAAA,OAAO,EAAE,IADiB;AAE1BC,UAAAA,IAAI,EAAE;AAAErC,YAAAA,YAAY,EAAEc;AAAhB;AAFoB,SAArB,CAAP;AAID;AACF,KATD;AAUD,GAtED,MAsEO;AACL,WAAOnG,GAAG,CAACuH,MAAJ,CAAW,GAAX,EAAgBC,IAAhB,CAAqB;AAAE;AAC5BC,MAAAA,OAAO,EAAE,IADiB;AAE1BC,MAAAA,IAAI,EAAE;AAAErC,QAAAA,YAAY,EAAEA;AAAhB;AAFoB,KAArB,CAAP;AAID;AACF,CAlQD","sourcesContent":["import path from 'path'\nimport slash from 'slash'\nimport { PdfReader } from \"pdfreader\"  //pacchetto usato per leggere i pdf \nimport fs from 'fs'//pacchetto usato per leggere docx files\nimport mammoth from 'mammoth' //pacchetto usato per convertire i docx in html\nimport WordExtractor from \"word-extractor\" //pacchetto usato per leggere i doc files\n//import libre from 'libreoffice-convert-win' //pacchetto usato per convertire i docx files in pdf (windows version)\nimport libre from 'libreoffice-convert' //pacchetto usato per convertire i docx files in pdf (linux version)\n\nconst environment = \"linux\"\n\nconst envSlash = (environment === \"windows\") ? \"\\\\\" : \"/\"\n\n// ----------------------------- [Responds with an Object for every document in Archive] -----------------------------    \n\nexport default async (req, res) => {\n  let conversionFinished = true\n  let isArchiveMapped //variabile bool che ci dirà se c'è una versione di oggi dell'archivio mappato\n  let mappedArchive //variabile array dei dati dell'archivio mappato\n  console.log(\"BACKEND - advancedSearch req.query:\", req.query)\n  const searchterms = req.query.searchterms && req.query.searchterms.length > 0 ? req.query.searchterms : null\n  const activeFilters = JSON.parse(req.query.activeFilters)\n  const filesToAnalyze = []\n  const dataToFilter = []\n  const todayDate = new Date()\n  const todayUTC = todayDate.toUTCString()\n  const readFileName = todayUTC.slice(0, 16)\n  try {\n    const mappedArchiveRaw = await fs.readFileSync(\"mappedArchive\" + envSlash + readFileName + \".json\")\n    mappedArchive = JSON.parse(mappedArchiveRaw)\n    isArchiveMapped = true\n    dataToFilter.push(...mappedArchive)\n  } catch (mappedArchiveMissing) {\n    console.log(mappedArchiveMissing)\n    isArchiveMapped = false\n  }\n\n  if (!isArchiveMapped) {\n    //funzione che estrae i path precisi di ogni file all'interno della dir archive\n    function* getFiles(dir) {\n      const dirents = fs.readdirSync(dir, { withFileTypes: true })\n      for (const dirent of dirents) {\n        const fullpath = path.resolve(dir, dirent.name)\n        if (dirent.isDirectory()) {\n          yield* getFiles(fullpath)\n        } else {\n          yield {\n            fullpath: fullpath,\n            linuxfullpath: slash(fullpath),\n            relativepath: fullpath.split(\"public\", envSlash)[1],\n            linuxpath: slash(fullpath.split(\"public\" + envSlash)[1]),\n            filename: dirent.name\n          }\n        }\n      }\n    }\n    (() => {\n      for (const f of getFiles('public/archive')) {\n        filesToAnalyze.push(f)\n      }\n    })()\n\n    //containerResult Promise starts pending\n    const containerResult = await new Promise((resolveContainer, rejectContainer) => {\n      try {\n        const analyzedFiles = []\n        filesToAnalyze.forEach(async (fileObj, fileIndex) => {\n          const pdf = fileObj.fullpath.toLowerCase().includes(\".pdf\")\n          const docx = fileObj.fullpath.toLowerCase().includes(\".docx\")\n          const doc = fileObj.fullpath.toLowerCase().includes(\".doc\")\n\n          //singleResult Promise starts pending\n          const singleResult = await new Promise((resolveSingle, rejectSingle) => {\n            if (pdf) { //[Pdf procedure] (PdfReader + manual array push)\n              if (!activeFilters.includePdf) resolveSingle({})\n              const pdfBuffer = fs.readFileSync(fileObj.fullpath)\n              const getPdfContent = async () => {\n                const pdfContentArray = []\n                await new PdfReader().parseFileItems(fileObj.fullpath, async (err, item) => {\n                  if (err) return rejectSingle(err) //rejecting singleResult Promise\n                  if (!item) { //Condizione d'uscita da parseFileItems()\n                    return resolveSingle({ //resolving singleResult Promise\n                      fullpath: fileObj.fullpath,\n                      linuxfullpath: fileObj.linuxfullpath,\n                      filename: fileObj.filename,\n                      relativepath: fileObj.relativepath,\n                      linuxpath: fileObj.linuxpath,\n                      content: pdfContentArray.join(\" \")\n                    })\n                  }\n                  if (item.text) { //Per ogni frammento del pdf, pusho in pdfContentArray.\n                    pdfContentArray.push(item.text)\n                    return true\n                  }\n                })\n              }\n              getPdfContent()\n            } else if (docx) {\n              if (!activeFilters.includeDocx) resolveSingle({})\n              //[Docx procedure] (mammoth)\n              const options = {}\n              mammoth.convertToHtml({ path: 'public' + envSlash + fileObj.relativepath }, options).then((mammothResult) => {\n                if (mammothResult.messages.length > 0) {\n                  for (let x; x < mammothResult.messages.length; x++) {\n                    console.log(\"\\n\\n Errors:\", mammothResult.messages[x], '\\n\\n')\n                  }\n                }\n                return resolveSingle({ //resolving singleResult Promise\n                  fullpath: fileObj.fullpath,\n                  linuxfullpath: fileObj.linuxfullpath,\n                  filename: fileObj.filename,\n                  relativepath: fileObj.relativepath,\n                  linuxpath: fileObj.linuxpath,\n                  content: mammothResult.value\n                })\n              })\n            } else if (doc) {\n              if (!activeFilters.includeDoc) resolveSingle({})\n              //[Doc procedure] (WordExtractor)\n              const getDocContent = async (fileObj) => {\n                const docExtractor = new WordExtractor()\n                const extractedContent = await docExtractor.extract('public' + envSlash + fileObj.relativepath).then(function (doc) {\n                  resolveSingle({ //resolving singleResult Promise\n                    fullpath: fileObj.fullpath,\n                    linuxfullpath: fileObj.linuxfullpath,\n                    filename: fileObj.filename,\n                    relativepath: fileObj.relativepath,\n                    linuxpath: fileObj.linuxpath,\n                    content: JSON.stringify(doc.getBody())\n                  })\n                })\n              }\n              getDocContent(fileObj)\n            } else {\n              rejectSingle(\"File is not pdf, docx or doc!\") //rejecting singleResult Promise\n            }\n          }).then(singleResult => {\n            return singleResult\n          })\n          //singleResult Promise resolved/rejected\n\n          await analyzedFiles.push({\n            fullpath: fileObj.fullpath,\n            filename: fileObj.filename,\n            relativepath: fileObj.relativepath,\n            linuxpath: fileObj.linuxpath,\n            content: (singleResult && singleResult.content) ? singleResult.content : \"\"\n          })\n\n          if (analyzedFiles.length === filesToAnalyze.length) {\n            //Qui dovrebbe salvare il json di containerResult\n            const mappedArchiveStr = JSON.stringify([...analyzedFiles])\n            console.log(\"|||||||||||||||||||||||| started writing a json file representing the archive\")\n            const todayDate = new Date()\n            const todayUTC = todayDate.toUTCString()\n            const writeFileName = todayUTC.slice(0, 16)\n            await fs.writeFileSync(\"mappedArchive\" + envSlash + writeFileName + \".json\", mappedArchiveStr)\n            console.log(\"|||||||||||||||||||||||| finished writing json file\")\n            resolveContainer(analyzedFiles) //resolving containerResult Promise\n          } else {\n            console.log(\"(analyzedFiles.length !== filesToAnalyze.length) fileIndex attuale:\", fileIndex)\n          }\n        })\n      } catch (errContainer) {\n        console.log(\"rejectContainer with error:\", errContainer)\n        rejectContainer(errContainer) //rejecting containerResult Promise\n      }\n    }).then((containerResult) => {\n      return containerResult\n    })//containerResult Promise resolved/rejected\n  }\n\n  const filteredDocs = dataToFilter.filter(d => {\n    if (d.content) {\n      if (!activeFilters.includePdf && d.filename.includes(\".pdf\")) return false\n      if (!activeFilters.includeDocx && d.filename.includes(\".docx\")) return false\n      if (!activeFilters.includeDoc && d.filename.includes(\".doc\") && d.filename.split(\".doc\")[1].length === 0) return false\n      //Eventuali affinamenti del filtro andranno qui \n      const cleanContent = d.content.replace(/[^\\w\\s]/gi, '').toLowerCase()\n      let result = null\n      if (activeFilters.indCorteCost) {\n        let target = \".ind corte\".replace(/[^\\w\\s]/gi, '')\n        result = cleanContent.includes(target)\n      } else {\n        result = cleanContent.includes(searchterms.replace(/[^\\w\\s]/gi, '').toLowerCase())\n      }\n      return result\n    } else {\n      return false\n    }\n  })\n\n  const checkIfConversionNeeded = (fileObjArr) => {\n    const names = fileObjArr.map(el => el.filename)\n    return names.some(name => (name.includes(\".docx\") || name.includes(\".doc\")))\n  }\n\n  if (checkIfConversionNeeded(filteredDocs)) {\n    let convertedDocs = []\n    conversionFinished = false\n\n    for (let x = 0; x < filteredDocs.length; x++) {\n      const d = filteredDocs[x]\n      const libreResult = await new Promise((resolveLibre, rejectLibre) => {\n        if (d && d.filename) {\n          const extend = '.pdf'\n          const enterPath = d.fullpath\n          const outputPath = d.filename.includes(\".docx\") ? d.fullpath.split('.docx')[0] + extend : d.fullpath.split('.doc')[0] + extend\n          const file = fs.readFileSync(enterPath)\n          libre.convert(file, extend, undefined, async (err, done) => {\n            if (err) {\n              console.log(`\\n\\n Error converting file: ${err} \\n\\n`)\n              rejectLibre(err)\n            } else {\n              // writeFileSync funziona, crea veramente il pdf, ma sarebbe troppo pesante farlo ogni volta per tutti i file, quindi mi limito a sfruttare il buffer: done.\n              //await fs.writeFileSync(outputPath, done)\n              resolveLibre(done)\n            }\n          })\n        } else {\n          console.log(\"Error - Caso inaspettato con questo file: \", filteredDocs[x])\n        }\n      }).then(libreResult => {\n        return libreResult\n      })\n\n      let mapResult = {}\n\n      if (libreResult && libreResult.byteLength) {\n        mapResult = {\n          fullpath: d.fullpath,\n          filename: d.filename,\n          relativepath: d.relativepath,\n          linuxpath: d.linuxpath,\n          content: d.filename.includes(\".docx\") ? d.content : \"\",\n          buffer: libreResult\n        }\n      } else {\n        mapResult = {\n          fullpath: d.fullpath,\n          filename: d.filename,\n          relativepath: d.relativepath,\n          linuxpath: d.linuxpath,\n          content: d.filename.includes(\".docx\") ? d.content : \"\"\n        }\n      }\n\n      const updateConvertedDocs = (convertedArr, originalArr) => {\n        const resultArr = [...convertedArr, mapResult]\n        if (resultArr.length === originalArr.length) {\n          conversionFinished = true\n        }\n        return resultArr\n      }\n      convertedDocs = await updateConvertedDocs(convertedDocs, filteredDocs)\n    }\n\n    (function forceWait() {\n      if (!conversionFinished) {\n        setTimeout(forceWait, 1000)\n      } else {\n        return res.status(200).json({ //Success - Trovato qualcosa per i searchterms immessi, e nessun errore.\n          success: true,\n          data: { filteredDocs: convertedDocs }\n        })\n      }\n    })()\n  } else {\n    return res.status(200).json({ //Success - Trovato qualcosa per i searchterms immessi, e nessun errore.\n      success: true,\n      data: { filteredDocs: filteredDocs }\n    })\n  }\n}"]},"metadata":{},"sourceType":"module"}